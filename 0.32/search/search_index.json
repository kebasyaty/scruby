{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Scruby","text":"<p> Asynchronous library for building and managing a hybrid database,by scheme of key-value. <p> </p> </p> <p>   The library uses fractal-tree addressing and      the search for documents based on the effect of a quantum loop.       The database consists of collections.      The maximum size of the one collection is 16**8=4294967296 branches,      each branch can store one or more keys.       The value of any key in collection can be obtained maximum in 8 steps,      thereby achieving high performance.       The effectiveness of the search for documents based on a quantum loop,      requires a large number of processor threads. </p>"},{"location":"#requirements","title":"Requirements","text":"<p>View the list of requirements.</p>"},{"location":"#changelog","title":"Changelog","text":"<p>View the change history.</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT.</p>"},{"location":"pages/aggregation/","title":"Aggregation classes","text":"<p>Aggregation classes.</p>"},{"location":"pages/aggregation/#scruby.aggregation.Average","title":"<code>Average</code>","text":"<p>Aggregation class for calculating the average value.</p> <p>Parameters:</p> Name Type Description Default <code>precision</code> <code>str</code> <p>The accuracy of rounding. <code>By default = .00</code></p> <code>'.00'</code> <code>rounding</code> <code>str</code> <p>Rounding mode. <code>By default = ROUND_HALF_EVEN</code></p> <code>ROUND_HALF_EVEN</code> Source code in <code>src/scruby/aggregation.py</code> <pre><code>class Average:\n    \"\"\"Aggregation class for calculating the average value.\n\n    Args:\n        precision: The accuracy of rounding. `By default = .00`\n        rounding: Rounding mode. `By default = ROUND_HALF_EVEN`\n    \"\"\"\n\n    def __init__(  # noqa: D107\n        self,\n        precision: str = \".00\",\n        rounding: str = ROUND_HALF_EVEN,\n    ) -&gt; None:\n        self.value = Decimal()\n        self.counter = 0\n        self.precision = precision\n        self.rounding = rounding\n\n    def set(self, number: int | float) -&gt; None:\n        \"\"\"Add value.\n\n        Args:\n            number: Current value (int | float).\n        \"\"\"\n        self.value += Decimal(str(number))\n        self.counter += 1\n\n    def get(self) -&gt; Decimal:\n        \"\"\"Get arithmetic average value.\n\n        Returns:\n            Number (Decimal) - Average value.\n        \"\"\"\n        return (self.value / Decimal(str(self.counter))).quantize(\n            exp=Decimal(self.precision),\n            rounding=self.rounding,\n        )\n</code></pre>"},{"location":"pages/aggregation/#scruby.aggregation.Average.get","title":"<code>get()</code>","text":"<p>Get arithmetic average value.</p> <p>Returns:</p> Type Description <code>Decimal</code> <p>Number (Decimal) - Average value.</p> Source code in <code>src/scruby/aggregation.py</code> <pre><code>def get(self) -&gt; Decimal:\n    \"\"\"Get arithmetic average value.\n\n    Returns:\n        Number (Decimal) - Average value.\n    \"\"\"\n    return (self.value / Decimal(str(self.counter))).quantize(\n        exp=Decimal(self.precision),\n        rounding=self.rounding,\n    )\n</code></pre>"},{"location":"pages/aggregation/#scruby.aggregation.Average.set","title":"<code>set(number)</code>","text":"<p>Add value.</p> <p>Parameters:</p> Name Type Description Default <code>number</code> <code>int | float</code> <p>Current value (int | float).</p> required Source code in <code>src/scruby/aggregation.py</code> <pre><code>def set(self, number: int | float) -&gt; None:\n    \"\"\"Add value.\n\n    Args:\n        number: Current value (int | float).\n    \"\"\"\n    self.value += Decimal(str(number))\n    self.counter += 1\n</code></pre>"},{"location":"pages/aggregation/#scruby.aggregation.Counter","title":"<code>Counter</code>","text":"<p>Aggregation class for calculating the number of documents.</p> <p>Parameters:</p> Name Type Description Default <code>limit</code> <code>int</code> <p>The maximum counter value.</p> <code>1000</code> Source code in <code>src/scruby/aggregation.py</code> <pre><code>class Counter:\n    \"\"\"Aggregation class for calculating the number of documents.\n\n    Args:\n        limit: The maximum counter value.\n    \"\"\"\n\n    def __init__(self, limit: int = 1000) -&gt; None:  # noqa: D107\n        self.limit = limit\n        self.counter = 0\n\n    def check(self) -&gt; bool:\n        \"\"\"Check the condition of the counter.\n\n        Returns:\n            Boolean value. If `True`, the maximum value is achieved.\n        \"\"\"\n        return self.counter &gt;= self.limit\n\n    def next(self) -&gt; None:\n        \"\"\"Increment the counter on one.\"\"\"\n        self.counter += 1\n</code></pre>"},{"location":"pages/aggregation/#scruby.aggregation.Counter.check","title":"<code>check()</code>","text":"<p>Check the condition of the counter.</p> <p>Returns:</p> Type Description <code>bool</code> <p>Boolean value. If <code>True</code>, the maximum value is achieved.</p> Source code in <code>src/scruby/aggregation.py</code> <pre><code>def check(self) -&gt; bool:\n    \"\"\"Check the condition of the counter.\n\n    Returns:\n        Boolean value. If `True`, the maximum value is achieved.\n    \"\"\"\n    return self.counter &gt;= self.limit\n</code></pre>"},{"location":"pages/aggregation/#scruby.aggregation.Counter.next","title":"<code>next()</code>","text":"<p>Increment the counter on one.</p> Source code in <code>src/scruby/aggregation.py</code> <pre><code>def next(self) -&gt; None:\n    \"\"\"Increment the counter on one.\"\"\"\n    self.counter += 1\n</code></pre>"},{"location":"pages/aggregation/#scruby.aggregation.Max","title":"<code>Max</code>","text":"<p>Aggregation class for calculating the maximum value.</p> Source code in <code>src/scruby/aggregation.py</code> <pre><code>class Max:\n    \"\"\"Aggregation class for calculating the maximum value.\"\"\"\n\n    def __init__(self) -&gt; None:  # noqa: D107\n        self.value: Any = 0\n\n    def set(self, number: int | float) -&gt; None:\n        \"\"\"Add value.\n\n        Args:\n            number: Current value.\n        \"\"\"\n        if number &gt; self.value:\n            self.value = number\n\n    def get(self) -&gt; Any:\n        \"\"\"Get maximum value.\n\n        Returns:\n            Number (int|float) - Maximum value.\n        \"\"\"\n        return self.value\n</code></pre>"},{"location":"pages/aggregation/#scruby.aggregation.Max.get","title":"<code>get()</code>","text":"<p>Get maximum value.</p> <p>Returns:</p> Type Description <code>Any</code> <p>Number (int|float) - Maximum value.</p> Source code in <code>src/scruby/aggregation.py</code> <pre><code>def get(self) -&gt; Any:\n    \"\"\"Get maximum value.\n\n    Returns:\n        Number (int|float) - Maximum value.\n    \"\"\"\n    return self.value\n</code></pre>"},{"location":"pages/aggregation/#scruby.aggregation.Max.set","title":"<code>set(number)</code>","text":"<p>Add value.</p> <p>Parameters:</p> Name Type Description Default <code>number</code> <code>int | float</code> <p>Current value.</p> required Source code in <code>src/scruby/aggregation.py</code> <pre><code>def set(self, number: int | float) -&gt; None:\n    \"\"\"Add value.\n\n    Args:\n        number: Current value.\n    \"\"\"\n    if number &gt; self.value:\n        self.value = number\n</code></pre>"},{"location":"pages/aggregation/#scruby.aggregation.Min","title":"<code>Min</code>","text":"<p>Aggregation class for calculating the minimum value.</p> Source code in <code>src/scruby/aggregation.py</code> <pre><code>class Min:\n    \"\"\"Aggregation class for calculating the minimum value.\"\"\"\n\n    def __init__(self) -&gt; None:  # noqa: D107\n        self.value: Any = 0\n\n    def set(self, number: int | float) -&gt; None:\n        \"\"\"Add value.\n\n        Args:\n            number: Current value.\n        \"\"\"\n        if self.value == 0 or number &lt; self.value:\n            self.value = number\n\n    def get(self) -&gt; Any:\n        \"\"\"Get minimum value.\n\n        Returns:\n            Number (int|float) - Minimum value.\n        \"\"\"\n        return self.value\n</code></pre>"},{"location":"pages/aggregation/#scruby.aggregation.Min.get","title":"<code>get()</code>","text":"<p>Get minimum value.</p> <p>Returns:</p> Type Description <code>Any</code> <p>Number (int|float) - Minimum value.</p> Source code in <code>src/scruby/aggregation.py</code> <pre><code>def get(self) -&gt; Any:\n    \"\"\"Get minimum value.\n\n    Returns:\n        Number (int|float) - Minimum value.\n    \"\"\"\n    return self.value\n</code></pre>"},{"location":"pages/aggregation/#scruby.aggregation.Min.set","title":"<code>set(number)</code>","text":"<p>Add value.</p> <p>Parameters:</p> Name Type Description Default <code>number</code> <code>int | float</code> <p>Current value.</p> required Source code in <code>src/scruby/aggregation.py</code> <pre><code>def set(self, number: int | float) -&gt; None:\n    \"\"\"Add value.\n\n    Args:\n        number: Current value.\n    \"\"\"\n    if self.value == 0 or number &lt; self.value:\n        self.value = number\n</code></pre>"},{"location":"pages/aggregation/#scruby.aggregation.Sum","title":"<code>Sum</code>","text":"<p>Aggregation class for calculating sum of values.</p> Source code in <code>src/scruby/aggregation.py</code> <pre><code>class Sum:\n    \"\"\"Aggregation class for calculating sum of values.\"\"\"\n\n    def __init__(self) -&gt; None:  # noqa: D107\n        self.value = Decimal()\n\n    def set(self, number: int | float) -&gt; None:\n        \"\"\"Add value.\n\n        Args:\n            number: Current value.\n        \"\"\"\n        self.value += Decimal(str(number))\n\n    def get(self) -&gt; Decimal:\n        \"\"\"Get sum of values.\n\n        Returns:\n            Number (int|float) - Sum of values.\n        \"\"\"\n        return self.value\n</code></pre>"},{"location":"pages/aggregation/#scruby.aggregation.Sum.get","title":"<code>get()</code>","text":"<p>Get sum of values.</p> <p>Returns:</p> Type Description <code>Decimal</code> <p>Number (int|float) - Sum of values.</p> Source code in <code>src/scruby/aggregation.py</code> <pre><code>def get(self) -&gt; Decimal:\n    \"\"\"Get sum of values.\n\n    Returns:\n        Number (int|float) - Sum of values.\n    \"\"\"\n    return self.value\n</code></pre>"},{"location":"pages/aggregation/#scruby.aggregation.Sum.set","title":"<code>set(number)</code>","text":"<p>Add value.</p> <p>Parameters:</p> Name Type Description Default <code>number</code> <code>int | float</code> <p>Current value.</p> required Source code in <code>src/scruby/aggregation.py</code> <pre><code>def set(self, number: int | float) -&gt; None:\n    \"\"\"Add value.\n\n    Args:\n        number: Current value.\n    \"\"\"\n    self.value += Decimal(str(number))\n</code></pre>"},{"location":"pages/db/","title":"Database","text":"<p>Creation and management of the database.</p>"},{"location":"pages/db/#scruby.db.Scruby","title":"<code>Scruby</code>","text":"<p>               Bases: <code>Keys</code>, <code>Find</code>, <code>CustomTask</code>, <code>Collection</code>, <code>Count</code>, <code>Delete</code>, <code>Update</code></p> <p>Creation and management of database.</p> Source code in <code>src/scruby/db.py</code> <pre><code>class Scruby(\n    mixins.Keys,\n    mixins.Find,\n    mixins.CustomTask,\n    mixins.Collection,\n    mixins.Count,\n    mixins.Delete,\n    mixins.Update,\n):\n    \"\"\"Creation and management of database.\"\"\"\n\n    def __init__(  # noqa: D107\n        self,\n    ) -&gt; None:\n        super().__init__()\n        self._meta = _Meta\n        self._db_root = settings.DB_ROOT\n        self._hash_reduce_left = settings.HASH_REDUCE_LEFT\n        self._max_workers = settings.MAX_WORKERS\n        # The maximum number of branches.\n        match self._hash_reduce_left:\n            case 0:\n                self._max_number_branch = 4294967296\n            case 2:\n                self._max_number_branch = 16777216\n            case 4:\n                self._max_number_branch = 65536\n            case 6:\n                self._max_number_branch = 256\n            case _ as unreachable:\n                msg: str = f\"{unreachable} - Unacceptable value for HASH_REDUCE_LEFT.\"\n                logging.critical(msg)\n                assert_never(Never(unreachable))  # pyrefly: ignore[not-callable]\n        # Plugins connection.\n        plugin_list: dict[str, Any] = {}\n        for plugin in settings.PLUGINS:\n            name = plugin.__name__\n            name = name[0].lower() + name[1:]\n            plugin_list[name] = plugin(self)\n        self.plugins = NamedTuple(**plugin_list)\n\n    @classmethod\n    async def collection(cls, class_model: Any) -&gt; Any:\n        \"\"\"Get an object to access a collection.\n\n        Args:\n            class_model (Any): Class of Model (ScrubyModel).\n\n        Returns:\n            Instance of Scruby for access a collection.\n        \"\"\"\n        if __debug__:\n            # Check if the object belongs to the class `ScrubyModel`\n            if ScrubyModel not in class_model.__bases__:\n                msg = (\n                    \"Method: `collection` =&gt; argument `class_model` \" + \"does not contain the base class `ScrubyModel`!\"\n                )\n                raise AssertionError(msg)\n            # Checking the model for the presence of a key.\n            model_fields = list(class_model.model_fields.keys())\n            if \"key\" not in model_fields:\n                msg = f\"Model: {class_model.__name__} =&gt; The `key` field is missing!\"\n                raise AssertionError(msg)\n            if \"created_at\" not in model_fields:\n                msg = f\"Model: {class_model.__name__} =&gt; The `created_at` field is missing!\"\n                raise AssertionError(msg)\n            if \"updated_at\" not in model_fields:\n                msg = f\"Model: {class_model.__name__} =&gt; The `updated_at` field is missing!\"\n                raise AssertionError(msg)\n            # Check the length of the collection name for an acceptable size.\n            len_db_root_absolut_path = len(str(await Path(settings.DB_ROOT).resolve()).encode(\"utf-8\"))\n            len_model_name = len(class_model.__name__)\n            len_full_path_leaf = len_db_root_absolut_path + len_model_name + 26\n            if len_full_path_leaf &gt; 255:\n                excess = len_full_path_leaf - 255\n                msg = (\n                    f\"Model: {class_model.__name__} =&gt; The collection name is too long, \"\n                    + f\"it exceeds the limit of {excess} characters!\"\n                )\n                raise AssertionError(msg)\n        # Create instance of Scruby\n        instance = cls()\n        # Add model class to Scruby\n        instance.__dict__[\"_class_model\"] = class_model\n        # Create a path for metadata.\n        meta_dir_path_tuple = (\n            settings.DB_ROOT,\n            class_model.__name__,\n            \"meta\",\n        )\n        instance.__dict__[\"_meta_path\"] = Path(\n            *meta_dir_path_tuple,\n            \"meta.json\",\n        )\n        # Create metadata for collection, if missing.\n        meta_dir_path = Path(*meta_dir_path_tuple)\n        if not await meta_dir_path.exists():\n            await meta_dir_path.mkdir(parents=True)\n            meta = _Meta(\n                db_root=settings.DB_ROOT,\n                collection_name=class_model.__name__,\n                hash_reduce_left=settings.HASH_REDUCE_LEFT,\n                max_branch_number=instance.__dict__[\"_max_number_branch\"],\n                counter_documents=0,\n            )\n            meta_json = meta.model_dump_json()\n            meta_path = Path(*(meta_dir_path, \"meta.json\"))\n            await meta_path.write_text(meta_json, \"utf-8\")\n        return instance\n\n    async def get_meta(self) -&gt; _Meta:\n        \"\"\"Asynchronous method for getting metadata of collection.\n\n        This method is for internal use.\n\n        Returns:\n            Metadata object.\n        \"\"\"\n        meta_json = await self._meta_path.read_text()\n        meta: _Meta = self._meta.model_validate_json(meta_json)\n        return meta\n\n    async def _set_meta(self, meta: _Meta) -&gt; None:\n        \"\"\"Asynchronous method for updating metadata of collection.\n\n        This method is for internal use.\n\n        Args:\n            meta (_Meta): Metadata of Collection.\n\n        Returns:\n            None.\n        \"\"\"\n        meta_json = meta.model_dump_json()\n        await self._meta_path.write_text(meta_json, \"utf-8\")\n\n    async def _counter_documents(self, step: Literal[1, -1]) -&gt; None:\n        \"\"\"Asynchronous method for management of documents in metadata of collection.\n\n        This method is for internal use.\n\n        Args:\n            step (Literal[1, -1]): Number of documents added or removed.\n\n        Returns:\n            None.\n        \"\"\"\n        meta_path = self._meta_path\n        meta_json = await meta_path.read_text(\"utf-8\")\n        meta: _Meta = self._meta.model_validate_json(meta_json)\n        meta.counter_documents += step\n        meta_json = meta.model_dump_json()\n        await meta_path.write_text(meta_json, \"utf-8\")\n\n    async def _get_leaf_path(self, key: str) -&gt; tuple[Path, str]:\n        \"\"\"Asynchronous method for getting path to collection cell by key.\n\n        This method is for internal use.\n\n        Args:\n            key (str): Key name.\n\n        Returns:\n            Path to cell of collection.\n        \"\"\"\n        if not isinstance(key, str):\n            msg = \"The key is not a string.\"\n            logging.error(msg)\n            raise KeyError(msg)\n        # Prepare key.\n        # Removes spaces at the beginning and end of a string.\n        # Replaces all whitespace characters with a single space.\n        prepared_key = re.sub(r\"\\s+\", \" \", key).strip().lower()\n        # Check the key for an empty string.\n        if len(prepared_key) == 0:\n            msg = \"The key should not be empty.\"\n            logging.error(msg)\n            raise KeyError(msg)\n        # Key to crc32 sum.\n        key_as_hash: str = f\"{zlib.crc32(prepared_key.encode('utf-8')):08x}\"[self._hash_reduce_left :]\n        # Convert crc32 sum in the segment of path.\n        separated_hash: str = \"/\".join(list(key_as_hash))\n        # The path of the branch to the database.\n        branch_path: Path = Path(\n            *(\n                self._db_root,\n                self._class_model.__name__,\n                separated_hash,\n            ),\n        )\n        # If the branch does not exist, need to create it.\n        if not await branch_path.exists():\n            await branch_path.mkdir(parents=True)\n        # The path to the database cell.\n        leaf_path: Path = Path(*(branch_path, \"leaf.json\"))\n        return (leaf_path, prepared_key)\n\n    @staticmethod\n    def napalm() -&gt; None:\n        \"\"\"Method for full database deletion.\n\n        The main purpose is tests.\n\n        Warning:\n            - `Be careful, this will remove all keys.`\n\n        Returns:\n            None.\n        \"\"\"\n        with contextlib.suppress(FileNotFoundError):\n            rmtree(settings.DB_ROOT)\n        return\n</code></pre>"},{"location":"pages/db/#scruby.db.Scruby.collection","title":"<code>collection(class_model)</code>  <code>async</code> <code>classmethod</code>","text":"<p>Get an object to access a collection.</p> <p>Parameters:</p> Name Type Description Default <code>class_model</code> <code>Any</code> <p>Class of Model (ScrubyModel).</p> required <p>Returns:</p> Type Description <code>Any</code> <p>Instance of Scruby for access a collection.</p> Source code in <code>src/scruby/db.py</code> <pre><code>@classmethod\nasync def collection(cls, class_model: Any) -&gt; Any:\n    \"\"\"Get an object to access a collection.\n\n    Args:\n        class_model (Any): Class of Model (ScrubyModel).\n\n    Returns:\n        Instance of Scruby for access a collection.\n    \"\"\"\n    if __debug__:\n        # Check if the object belongs to the class `ScrubyModel`\n        if ScrubyModel not in class_model.__bases__:\n            msg = (\n                \"Method: `collection` =&gt; argument `class_model` \" + \"does not contain the base class `ScrubyModel`!\"\n            )\n            raise AssertionError(msg)\n        # Checking the model for the presence of a key.\n        model_fields = list(class_model.model_fields.keys())\n        if \"key\" not in model_fields:\n            msg = f\"Model: {class_model.__name__} =&gt; The `key` field is missing!\"\n            raise AssertionError(msg)\n        if \"created_at\" not in model_fields:\n            msg = f\"Model: {class_model.__name__} =&gt; The `created_at` field is missing!\"\n            raise AssertionError(msg)\n        if \"updated_at\" not in model_fields:\n            msg = f\"Model: {class_model.__name__} =&gt; The `updated_at` field is missing!\"\n            raise AssertionError(msg)\n        # Check the length of the collection name for an acceptable size.\n        len_db_root_absolut_path = len(str(await Path(settings.DB_ROOT).resolve()).encode(\"utf-8\"))\n        len_model_name = len(class_model.__name__)\n        len_full_path_leaf = len_db_root_absolut_path + len_model_name + 26\n        if len_full_path_leaf &gt; 255:\n            excess = len_full_path_leaf - 255\n            msg = (\n                f\"Model: {class_model.__name__} =&gt; The collection name is too long, \"\n                + f\"it exceeds the limit of {excess} characters!\"\n            )\n            raise AssertionError(msg)\n    # Create instance of Scruby\n    instance = cls()\n    # Add model class to Scruby\n    instance.__dict__[\"_class_model\"] = class_model\n    # Create a path for metadata.\n    meta_dir_path_tuple = (\n        settings.DB_ROOT,\n        class_model.__name__,\n        \"meta\",\n    )\n    instance.__dict__[\"_meta_path\"] = Path(\n        *meta_dir_path_tuple,\n        \"meta.json\",\n    )\n    # Create metadata for collection, if missing.\n    meta_dir_path = Path(*meta_dir_path_tuple)\n    if not await meta_dir_path.exists():\n        await meta_dir_path.mkdir(parents=True)\n        meta = _Meta(\n            db_root=settings.DB_ROOT,\n            collection_name=class_model.__name__,\n            hash_reduce_left=settings.HASH_REDUCE_LEFT,\n            max_branch_number=instance.__dict__[\"_max_number_branch\"],\n            counter_documents=0,\n        )\n        meta_json = meta.model_dump_json()\n        meta_path = Path(*(meta_dir_path, \"meta.json\"))\n        await meta_path.write_text(meta_json, \"utf-8\")\n    return instance\n</code></pre>"},{"location":"pages/db/#scruby.db.Scruby.get_meta","title":"<code>get_meta()</code>  <code>async</code>","text":"<p>Asynchronous method for getting metadata of collection.</p> <p>This method is for internal use.</p> <p>Returns:</p> Type Description <code>_Meta</code> <p>Metadata object.</p> Source code in <code>src/scruby/db.py</code> <pre><code>async def get_meta(self) -&gt; _Meta:\n    \"\"\"Asynchronous method for getting metadata of collection.\n\n    This method is for internal use.\n\n    Returns:\n        Metadata object.\n    \"\"\"\n    meta_json = await self._meta_path.read_text()\n    meta: _Meta = self._meta.model_validate_json(meta_json)\n    return meta\n</code></pre>"},{"location":"pages/db/#scruby.db.Scruby.napalm","title":"<code>napalm()</code>  <code>staticmethod</code>","text":"<p>Method for full database deletion.</p> <p>The main purpose is tests.</p> Warning <ul> <li><code>Be careful, this will remove all keys.</code></li> </ul> <p>Returns:</p> Type Description <code>None</code> <p>None.</p> Source code in <code>src/scruby/db.py</code> <pre><code>@staticmethod\ndef napalm() -&gt; None:\n    \"\"\"Method for full database deletion.\n\n    The main purpose is tests.\n\n    Warning:\n        - `Be careful, this will remove all keys.`\n\n    Returns:\n        None.\n    \"\"\"\n    with contextlib.suppress(FileNotFoundError):\n        rmtree(settings.DB_ROOT)\n    return\n</code></pre>"},{"location":"pages/db/#scruby.db.ScrubyModel","title":"<code>ScrubyModel</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Additional fields for models.</p> Source code in <code>src/scruby/db.py</code> <pre><code>class ScrubyModel(BaseModel):\n    \"\"\"Additional fields for models.\"\"\"\n\n    created_at: datetime | None = None\n    updated_at: datetime | None = None\n</code></pre>"},{"location":"pages/errors/","title":"Errors","text":"<p>Scruby Exceptions.</p>"},{"location":"pages/errors/#scruby.errors.KeyAlreadyExistsError","title":"<code>KeyAlreadyExistsError</code>","text":"<p>               Bases: <code>ScrubyException</code></p> <p>Exception is raised if the key already exists.</p> Source code in <code>src/scruby/errors.py</code> <pre><code>class KeyAlreadyExistsError(ScrubyException):\n    \"\"\"Exception is raised if the key already exists.\"\"\"\n\n    def __init__(self) -&gt; None:  # noqa: D107\n        self.message = \"The key already exists.\"\n        super().__init__(self.message)\n</code></pre>"},{"location":"pages/errors/#scruby.errors.KeyNotExistsError","title":"<code>KeyNotExistsError</code>","text":"<p>               Bases: <code>ScrubyException</code></p> <p>Exception is raised If the key is not exists.</p> Source code in <code>src/scruby/errors.py</code> <pre><code>class KeyNotExistsError(ScrubyException):\n    \"\"\"Exception is raised If the key is not exists.\"\"\"\n\n    def __init__(self) -&gt; None:  # noqa: D107\n        self.message = \"The key not exists.\"\n        super().__init__(self.message)\n</code></pre>"},{"location":"pages/errors/#scruby.errors.MetadataValueError","title":"<code>MetadataValueError</code>","text":"<p>               Bases: <code>ScrubyException</code></p> <p>Exception is raised if value of variable in metadata does not matching expected.</p> Source code in <code>src/scruby/errors.py</code> <pre><code>class MetadataValueError(ScrubyException):\n    \"\"\"Exception is raised if value of variable in metadata does not matching expected.\"\"\"\n\n    def __init__(self, message: str) -&gt; None:  # noqa: D107\n        self.message = message\n        super().__init__(self.message)\n</code></pre>"},{"location":"pages/errors/#scruby.errors.ScrubyException","title":"<code>ScrubyException</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Root Custom Exception.</p> Source code in <code>src/scruby/errors.py</code> <pre><code>class ScrubyException(Exception):\n    \"\"\"Root Custom Exception.\"\"\"\n\n    def __init__(self, *args, **kwargs) -&gt; None:  # type: ignore[no-untyped-def]  # noqa: D107\n        super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"pages/installation/","title":"Installation","text":"<pre><code>uv add scruby\n</code></pre> <pre><code># Run Development:\nuv run python main.py\n# Run Production:\nuv run python -OOP main.py\n</code></pre>"},{"location":"pages/settings/","title":"Settings","text":"<p>Database settings.</p> <p>The module contains the following parameters:</p> <ul> <li><code>DB_ROOT</code> - Path to root directory of database. <code>By default = \"ScrubyDB\" (in root of project)</code>.</li> <li><code>HASH_REDUCE_LEFT</code> - The length of the hash reduction on the left side.<ul> <li><code>0</code> - 4294967296 branches in collection.</li> <li><code>2</code> - 16777216 branches in collection.</li> <li><code>4</code> - 65536 branches in collection.</li> <li><code>6</code> - 256 branches in collection (by default).</li> </ul> </li> <li><code>MAX_WORKERS</code> - The maximum number of processes that can be used <code>By default = None</code>.</li> <li><code>PLUGINS</code> - For adding plugins.</li> </ul> <p> Hint:  Number of branches is number of requests to the hard disk during quantum operations.  Quantum operations: find_one, find_many, count_documents, delete_many, run_custom_task. </p> <p> MAX_WORKERS (clarification): The maximum number of processes that can be used to execute the given calls. If None, then as many worker processes will be reated as the machine has processors. </p>"},{"location":"pages/mixins/","title":"Mixins","text":"<p>Mixins - Methods for the Scruby class.</p>"},{"location":"pages/mixins/collection/","title":"Collection","text":"<p>Methods for working with collections.</p>"},{"location":"pages/mixins/collection/#scruby.mixins.collection.Collection","title":"<code>Collection</code>","text":"<p>Methods for working with collections.</p> Source code in <code>src/scruby/mixins/collection.py</code> <pre><code>class Collection:\n    \"\"\"Methods for working with collections.\"\"\"\n\n    def collection_name(self) -&gt; str:\n        \"\"\"Get collection name.\n\n        Returns:\n            Collection name.\n        \"\"\"\n        return self._class_model.__name__\n\n    @staticmethod\n    async def collection_list() -&gt; list[str]:\n        \"\"\"Get collection list.\"\"\"\n        target_directory = Path(settings.DB_ROOT)\n        # Get all entries in the directory\n        all_entries = Path.iterdir(target_directory)\n        directory_names: list[str] = [entry.name async for entry in all_entries]\n        return directory_names\n\n    @staticmethod\n    async def delete_collection(name: str) -&gt; None:\n        \"\"\"Asynchronous method for deleting a collection by its name.\n\n        Args:\n            name (str): Collection name.\n\n        Returns:\n            None.\n        \"\"\"\n        target_directory = f\"{settings.DB_ROOT}/{name}\"\n        await to_thread.run_sync(rmtree, target_directory)  # pyrefly: ignore[bad-argument-type]\n        return\n</code></pre>"},{"location":"pages/mixins/collection/#scruby.mixins.collection.Collection.collection_list","title":"<code>collection_list()</code>  <code>async</code> <code>staticmethod</code>","text":"<p>Get collection list.</p> Source code in <code>src/scruby/mixins/collection.py</code> <pre><code>@staticmethod\nasync def collection_list() -&gt; list[str]:\n    \"\"\"Get collection list.\"\"\"\n    target_directory = Path(settings.DB_ROOT)\n    # Get all entries in the directory\n    all_entries = Path.iterdir(target_directory)\n    directory_names: list[str] = [entry.name async for entry in all_entries]\n    return directory_names\n</code></pre>"},{"location":"pages/mixins/collection/#scruby.mixins.collection.Collection.collection_name","title":"<code>collection_name()</code>","text":"<p>Get collection name.</p> <p>Returns:</p> Type Description <code>str</code> <p>Collection name.</p> Source code in <code>src/scruby/mixins/collection.py</code> <pre><code>def collection_name(self) -&gt; str:\n    \"\"\"Get collection name.\n\n    Returns:\n        Collection name.\n    \"\"\"\n    return self._class_model.__name__\n</code></pre>"},{"location":"pages/mixins/collection/#scruby.mixins.collection.Collection.delete_collection","title":"<code>delete_collection(name)</code>  <code>async</code> <code>staticmethod</code>","text":"<p>Asynchronous method for deleting a collection by its name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Collection name.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None.</p> Source code in <code>src/scruby/mixins/collection.py</code> <pre><code>@staticmethod\nasync def delete_collection(name: str) -&gt; None:\n    \"\"\"Asynchronous method for deleting a collection by its name.\n\n    Args:\n        name (str): Collection name.\n\n    Returns:\n        None.\n    \"\"\"\n    target_directory = f\"{settings.DB_ROOT}/{name}\"\n    await to_thread.run_sync(rmtree, target_directory)  # pyrefly: ignore[bad-argument-type]\n    return\n</code></pre>"},{"location":"pages/mixins/count/","title":"Count","text":"<p>Methods for counting the number of documents.</p>"},{"location":"pages/mixins/count/#scruby.mixins.count.Count","title":"<code>Count</code>","text":"<p>Methods for counting the number of documents.</p> Source code in <code>src/scruby/mixins/count.py</code> <pre><code>class Count:\n    \"\"\"Methods for counting the number of documents.\"\"\"\n\n    async def estimated_document_count(self) -&gt; int:\n        \"\"\"Get an estimate of the number of documents in this collection using collection metadata.\n\n        Returns:\n            The number of documents.\n        \"\"\"\n        meta = await self.get_meta()\n        return meta.counter_documents\n\n    async def count_documents(\n        self,\n        filter_fn: Callable,\n    ) -&gt; int:\n        \"\"\"Count the number of documents a matching the filter in this collection.\n\n        Attention:\n            - The search is based on the effect of a quantum loop.\n            - The search effectiveness depends on the number of processor threads.\n\n        Args:\n            filter_fn (Callable): A function that execute the conditions of filtering.\n\n        Returns:\n            The number of documents.\n        \"\"\"\n        # Variable initialization\n        search_task_fn: Callable = self._task_find\n        branch_numbers: range = range(self._max_number_branch)\n        hash_reduce_left: int = self._hash_reduce_left\n        db_root: str = self._db_root\n        class_model: Any = self._class_model\n        counter: int = 0\n        # Run quantum loop\n        with concurrent.futures.ThreadPoolExecutor(self._max_workers) as executor:\n            for branch_number in branch_numbers:\n                future = executor.submit(\n                    search_task_fn,\n                    branch_number,\n                    filter_fn,\n                    hash_reduce_left,\n                    db_root,\n                    class_model,\n                )\n                if await future.result() is not None:\n                    counter += 1\n        return counter\n</code></pre>"},{"location":"pages/mixins/count/#scruby.mixins.count.Count.count_documents","title":"<code>count_documents(filter_fn)</code>  <code>async</code>","text":"<p>Count the number of documents a matching the filter in this collection.</p> Attention <ul> <li>The search is based on the effect of a quantum loop.</li> <li>The search effectiveness depends on the number of processor threads.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>filter_fn</code> <code>Callable</code> <p>A function that execute the conditions of filtering.</p> required <p>Returns:</p> Type Description <code>int</code> <p>The number of documents.</p> Source code in <code>src/scruby/mixins/count.py</code> <pre><code>async def count_documents(\n    self,\n    filter_fn: Callable,\n) -&gt; int:\n    \"\"\"Count the number of documents a matching the filter in this collection.\n\n    Attention:\n        - The search is based on the effect of a quantum loop.\n        - The search effectiveness depends on the number of processor threads.\n\n    Args:\n        filter_fn (Callable): A function that execute the conditions of filtering.\n\n    Returns:\n        The number of documents.\n    \"\"\"\n    # Variable initialization\n    search_task_fn: Callable = self._task_find\n    branch_numbers: range = range(self._max_number_branch)\n    hash_reduce_left: int = self._hash_reduce_left\n    db_root: str = self._db_root\n    class_model: Any = self._class_model\n    counter: int = 0\n    # Run quantum loop\n    with concurrent.futures.ThreadPoolExecutor(self._max_workers) as executor:\n        for branch_number in branch_numbers:\n            future = executor.submit(\n                search_task_fn,\n                branch_number,\n                filter_fn,\n                hash_reduce_left,\n                db_root,\n                class_model,\n            )\n            if await future.result() is not None:\n                counter += 1\n    return counter\n</code></pre>"},{"location":"pages/mixins/count/#scruby.mixins.count.Count.estimated_document_count","title":"<code>estimated_document_count()</code>  <code>async</code>","text":"<p>Get an estimate of the number of documents in this collection using collection metadata.</p> <p>Returns:</p> Type Description <code>int</code> <p>The number of documents.</p> Source code in <code>src/scruby/mixins/count.py</code> <pre><code>async def estimated_document_count(self) -&gt; int:\n    \"\"\"Get an estimate of the number of documents in this collection using collection metadata.\n\n    Returns:\n        The number of documents.\n    \"\"\"\n    meta = await self.get_meta()\n    return meta.counter_documents\n</code></pre>"},{"location":"pages/mixins/custom_task/","title":"Custom Task","text":"<p>Quantum methods for running custom tasks.</p>"},{"location":"pages/mixins/custom_task/#scruby.mixins.custom_task.CustomTask","title":"<code>CustomTask</code>","text":"<p>Quantum methods for running custom tasks.</p> Source code in <code>src/scruby/mixins/custom_task.py</code> <pre><code>class CustomTask:\n    \"\"\"Quantum methods for running custom tasks.\"\"\"\n\n    async def run_custom_task(\n        self,\n        custom_task_fn: Callable,\n        filter_fn: Callable = lambda _: True,\n        **kwargs,\n    ) -&gt; Any:\n        \"\"\"Running custom task.\n\n        Attention:\n            - The search is based on the effect of a quantum loop.\n            - The search effectiveness depends on the number of processor threads.\n\n        Args:\n            custom_task_fn (Callable): A function that execute the custom task.\n\n        Returns:\n            The result of a custom task.\n        \"\"\"\n        return await custom_task_fn(\n            search_task_fn=self._task_find,\n            filter_fn=filter_fn,\n            branch_numbers=range(self._max_number_branch),\n            hash_reduce_left=self._hash_reduce_left,\n            db_root=self._db_root,\n            class_model=self._class_model,\n            max_workers=self._max_workers,\n            **kwargs,\n        )\n</code></pre>"},{"location":"pages/mixins/custom_task/#scruby.mixins.custom_task.CustomTask.run_custom_task","title":"<code>run_custom_task(custom_task_fn, filter_fn=lambda _: True, **kwargs)</code>  <code>async</code>","text":"<p>Running custom task.</p> Attention <ul> <li>The search is based on the effect of a quantum loop.</li> <li>The search effectiveness depends on the number of processor threads.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>custom_task_fn</code> <code>Callable</code> <p>A function that execute the custom task.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The result of a custom task.</p> Source code in <code>src/scruby/mixins/custom_task.py</code> <pre><code>async def run_custom_task(\n    self,\n    custom_task_fn: Callable,\n    filter_fn: Callable = lambda _: True,\n    **kwargs,\n) -&gt; Any:\n    \"\"\"Running custom task.\n\n    Attention:\n        - The search is based on the effect of a quantum loop.\n        - The search effectiveness depends on the number of processor threads.\n\n    Args:\n        custom_task_fn (Callable): A function that execute the custom task.\n\n    Returns:\n        The result of a custom task.\n    \"\"\"\n    return await custom_task_fn(\n        search_task_fn=self._task_find,\n        filter_fn=filter_fn,\n        branch_numbers=range(self._max_number_branch),\n        hash_reduce_left=self._hash_reduce_left,\n        db_root=self._db_root,\n        class_model=self._class_model,\n        max_workers=self._max_workers,\n        **kwargs,\n    )\n</code></pre>"},{"location":"pages/mixins/delete/","title":"Delete","text":"<p>Methods for deleting documents.</p>"},{"location":"pages/mixins/delete/#scruby.mixins.delete.Delete","title":"<code>Delete</code>","text":"<p>Methods for deleting documents.</p> Source code in <code>src/scruby/mixins/delete.py</code> <pre><code>class Delete:\n    \"\"\"Methods for deleting documents.\"\"\"\n\n    @staticmethod\n    async def _task_delete(\n        branch_number: int,\n        filter_fn: Callable,\n        hash_reduce_left: int,\n        db_root: str,\n        class_model: Any,\n    ) -&gt; int:\n        \"\"\"Task for find and delete documents.\n\n        This method is for internal use.\n\n        Returns:\n            The number of deleted documents.\n        \"\"\"\n        branch_number_as_hash: str = f\"{branch_number:08x}\"[hash_reduce_left:]\n        separated_hash: str = \"/\".join(list(branch_number_as_hash))\n        leaf_path: Path = Path(\n            *(\n                db_root,\n                class_model.__name__,\n                separated_hash,\n                \"leaf.json\",\n            ),\n        )\n        counter: int = 0\n        if await leaf_path.exists():\n            data_json: bytes = await leaf_path.read_bytes()\n            data: dict[str, str] = orjson.loads(data_json) or {}\n            new_state: dict[str, str] = {}\n            for key, val in data.items():\n                doc = class_model.model_validate_json(val)\n                if filter_fn(doc):\n                    counter -= 1\n                else:\n                    new_state[key] = val\n            await leaf_path.write_bytes(orjson.dumps(new_state))\n        return counter\n\n    async def delete_many(\n        self,\n        filter_fn: Callable,\n    ) -&gt; int:\n        \"\"\"Delete one or more documents matching the filter.\n\n        Attention:\n            - The search is based on the effect of a quantum loop.\n            - The search effectiveness depends on the number of processor threads.\n\n        Args:\n            filter_fn (Callable): A function that execute the conditions of filtering.\n\n        Returns:\n            The number of deleted documents.\n        \"\"\"\n        # Variable initialization\n        search_task_fn: Callable = self._task_delete\n        branch_numbers: range = range(self._max_number_branch)\n        hash_reduce_left: int = self._hash_reduce_left\n        db_root: str = self._db_root\n        class_model: Any = self._class_model\n        counter: int = 0\n        # Run quantum loop\n        with concurrent.futures.ThreadPoolExecutor(self._max_workers) as executor:\n            for branch_number in branch_numbers:\n                future = executor.submit(\n                    search_task_fn,\n                    branch_number,\n                    filter_fn,\n                    hash_reduce_left,\n                    db_root,\n                    class_model,\n                )\n                counter += await future.result()\n        if counter &lt; 0:\n            await self._counter_documents(counter)\n        return abs(counter)\n</code></pre>"},{"location":"pages/mixins/delete/#scruby.mixins.delete.Delete.delete_many","title":"<code>delete_many(filter_fn)</code>  <code>async</code>","text":"<p>Delete one or more documents matching the filter.</p> Attention <ul> <li>The search is based on the effect of a quantum loop.</li> <li>The search effectiveness depends on the number of processor threads.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>filter_fn</code> <code>Callable</code> <p>A function that execute the conditions of filtering.</p> required <p>Returns:</p> Type Description <code>int</code> <p>The number of deleted documents.</p> Source code in <code>src/scruby/mixins/delete.py</code> <pre><code>async def delete_many(\n    self,\n    filter_fn: Callable,\n) -&gt; int:\n    \"\"\"Delete one or more documents matching the filter.\n\n    Attention:\n        - The search is based on the effect of a quantum loop.\n        - The search effectiveness depends on the number of processor threads.\n\n    Args:\n        filter_fn (Callable): A function that execute the conditions of filtering.\n\n    Returns:\n        The number of deleted documents.\n    \"\"\"\n    # Variable initialization\n    search_task_fn: Callable = self._task_delete\n    branch_numbers: range = range(self._max_number_branch)\n    hash_reduce_left: int = self._hash_reduce_left\n    db_root: str = self._db_root\n    class_model: Any = self._class_model\n    counter: int = 0\n    # Run quantum loop\n    with concurrent.futures.ThreadPoolExecutor(self._max_workers) as executor:\n        for branch_number in branch_numbers:\n            future = executor.submit(\n                search_task_fn,\n                branch_number,\n                filter_fn,\n                hash_reduce_left,\n                db_root,\n                class_model,\n            )\n            counter += await future.result()\n    if counter &lt; 0:\n        await self._counter_documents(counter)\n    return abs(counter)\n</code></pre>"},{"location":"pages/mixins/find/","title":"Find","text":"<p>Quantum methods for searching documents.</p>"},{"location":"pages/mixins/find/#scruby.mixins.find.Find","title":"<code>Find</code>","text":"<p>Quantum methods for searching documents.</p> Source code in <code>src/scruby/mixins/find.py</code> <pre><code>class Find:\n    \"\"\"Quantum methods for searching documents.\"\"\"\n\n    @staticmethod\n    async def _task_find(\n        branch_number: int,\n        filter_fn: Callable,\n        hash_reduce_left: str,\n        db_root: str,\n        class_model: Any,\n    ) -&gt; list[Any] | None:\n        \"\"\"Task for find documents.\n\n        This method is for internal use.\n\n        Returns:\n            List of documents or None.\n        \"\"\"\n        branch_number_as_hash: str = f\"{branch_number:08x}\"[hash_reduce_left:]\n        separated_hash: str = \"/\".join(list(branch_number_as_hash))\n        leaf_path: Path = Path(\n            *(\n                db_root,\n                class_model.__name__,\n                separated_hash,\n                \"leaf.json\",\n            ),\n        )\n        docs: list[Any] = []\n        if await leaf_path.exists():\n            data_json: bytes = await leaf_path.read_bytes()\n            data: dict[str, str] = orjson.loads(data_json) or {}\n            for _, val in data.items():\n                doc = class_model.model_validate_json(val)\n                if filter_fn(doc):\n                    docs.append(doc)\n        return docs or None\n\n    async def find_one(\n        self,\n        filter_fn: Callable,\n    ) -&gt; Any | None:\n        \"\"\"Find one document matching the filter.\n\n        Attention:\n            - The search is based on the effect of a quantum loop.\n            - The search effectiveness depends on the number of processor threads.\n\n        Args:\n            filter_fn (Callable): A function that execute the conditions of filtering.\n\n        Returns:\n            Document or None.\n        \"\"\"\n        # Variable initialization\n        search_task_fn: Callable = self._task_find\n        branch_numbers: range = range(self._max_number_branch)\n        hash_reduce_left: int = self._hash_reduce_left\n        db_root: str = self._db_root\n        class_model: Any = self._class_model\n        # Run quantum loop\n        with concurrent.futures.ThreadPoolExecutor(self._max_workers) as executor:\n            for branch_number in branch_numbers:\n                future = executor.submit(\n                    search_task_fn,\n                    branch_number,\n                    filter_fn,\n                    hash_reduce_left,\n                    db_root,\n                    class_model,\n                )\n                docs = await future.result()\n                if docs is not None:\n                    return docs[0]\n        return None\n\n    async def find_many(\n        self,\n        filter_fn: Callable = lambda _: True,\n        limit_docs: int = 100,\n        page_number: int = 1,\n    ) -&gt; list[Any] | None:\n        \"\"\"Find many documents matching the filter.\n\n        Attention:\n            - The search is based on the effect of a quantum loop.\n            - The search effectiveness depends on the number of processor threads.\n\n        Args:\n            filter_fn (Callable): A function that execute the conditions of filtering.\n                                  By default it searches for all documents.\n            limit_docs (int): Limiting the number of documents. By default = 100.\n            page_number (int): For pagination. By default = 1.\n                               Number of documents per page = limit_docs.\n\n        Returns:\n            List of documents or None.\n        \"\"\"\n        # The `page_number` parameter must not be less than one\n        assert page_number &gt; 0, \"`find_many` =&gt; The `page_number` parameter must not be less than one.\"\n        # Variable initialization\n        search_task_fn: Callable = self._task_find\n        branch_numbers: range = range(self._max_number_branch)\n        hash_reduce_left: int = self._hash_reduce_left\n        db_root: str = self._db_root\n        class_model: Any = self._class_model\n        counter: int = 0\n        number_docs_skippe: int = limit_docs * (page_number - 1) if page_number &gt; 1 else 0\n        result: list[Any] = []\n        # Run quantum loop\n        with concurrent.futures.ThreadPoolExecutor(self._max_workers) as executor:\n            for branch_number in branch_numbers:\n                if number_docs_skippe == 0 and counter &gt;= limit_docs:\n                    return result[:limit_docs]\n                future = executor.submit(\n                    search_task_fn,\n                    branch_number,\n                    filter_fn,\n                    hash_reduce_left,\n                    db_root,\n                    class_model,\n                )\n                docs = await future.result()\n                if docs is not None:\n                    for doc in docs:\n                        if number_docs_skippe == 0:\n                            if counter &gt;= limit_docs:\n                                return result[:limit_docs]\n                            result.append(doc)\n                            counter += 1\n                        else:\n                            number_docs_skippe -= 1\n        return result or None\n</code></pre>"},{"location":"pages/mixins/find/#scruby.mixins.find.Find.find_many","title":"<code>find_many(filter_fn=lambda _: True, limit_docs=100, page_number=1)</code>  <code>async</code>","text":"<p>Find many documents matching the filter.</p> Attention <ul> <li>The search is based on the effect of a quantum loop.</li> <li>The search effectiveness depends on the number of processor threads.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>filter_fn</code> <code>Callable</code> <p>A function that execute the conditions of filtering.                   By default it searches for all documents.</p> <code>lambda _: True</code> <code>limit_docs</code> <code>int</code> <p>Limiting the number of documents. By default = 100.</p> <code>100</code> <code>page_number</code> <code>int</code> <p>For pagination. By default = 1.                Number of documents per page = limit_docs.</p> <code>1</code> <p>Returns:</p> Type Description <code>list[Any] | None</code> <p>List of documents or None.</p> Source code in <code>src/scruby/mixins/find.py</code> <pre><code>async def find_many(\n    self,\n    filter_fn: Callable = lambda _: True,\n    limit_docs: int = 100,\n    page_number: int = 1,\n) -&gt; list[Any] | None:\n    \"\"\"Find many documents matching the filter.\n\n    Attention:\n        - The search is based on the effect of a quantum loop.\n        - The search effectiveness depends on the number of processor threads.\n\n    Args:\n        filter_fn (Callable): A function that execute the conditions of filtering.\n                              By default it searches for all documents.\n        limit_docs (int): Limiting the number of documents. By default = 100.\n        page_number (int): For pagination. By default = 1.\n                           Number of documents per page = limit_docs.\n\n    Returns:\n        List of documents or None.\n    \"\"\"\n    # The `page_number` parameter must not be less than one\n    assert page_number &gt; 0, \"`find_many` =&gt; The `page_number` parameter must not be less than one.\"\n    # Variable initialization\n    search_task_fn: Callable = self._task_find\n    branch_numbers: range = range(self._max_number_branch)\n    hash_reduce_left: int = self._hash_reduce_left\n    db_root: str = self._db_root\n    class_model: Any = self._class_model\n    counter: int = 0\n    number_docs_skippe: int = limit_docs * (page_number - 1) if page_number &gt; 1 else 0\n    result: list[Any] = []\n    # Run quantum loop\n    with concurrent.futures.ThreadPoolExecutor(self._max_workers) as executor:\n        for branch_number in branch_numbers:\n            if number_docs_skippe == 0 and counter &gt;= limit_docs:\n                return result[:limit_docs]\n            future = executor.submit(\n                search_task_fn,\n                branch_number,\n                filter_fn,\n                hash_reduce_left,\n                db_root,\n                class_model,\n            )\n            docs = await future.result()\n            if docs is not None:\n                for doc in docs:\n                    if number_docs_skippe == 0:\n                        if counter &gt;= limit_docs:\n                            return result[:limit_docs]\n                        result.append(doc)\n                        counter += 1\n                    else:\n                        number_docs_skippe -= 1\n    return result or None\n</code></pre>"},{"location":"pages/mixins/find/#scruby.mixins.find.Find.find_one","title":"<code>find_one(filter_fn)</code>  <code>async</code>","text":"<p>Find one document matching the filter.</p> Attention <ul> <li>The search is based on the effect of a quantum loop.</li> <li>The search effectiveness depends on the number of processor threads.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>filter_fn</code> <code>Callable</code> <p>A function that execute the conditions of filtering.</p> required <p>Returns:</p> Type Description <code>Any | None</code> <p>Document or None.</p> Source code in <code>src/scruby/mixins/find.py</code> <pre><code>async def find_one(\n    self,\n    filter_fn: Callable,\n) -&gt; Any | None:\n    \"\"\"Find one document matching the filter.\n\n    Attention:\n        - The search is based on the effect of a quantum loop.\n        - The search effectiveness depends on the number of processor threads.\n\n    Args:\n        filter_fn (Callable): A function that execute the conditions of filtering.\n\n    Returns:\n        Document or None.\n    \"\"\"\n    # Variable initialization\n    search_task_fn: Callable = self._task_find\n    branch_numbers: range = range(self._max_number_branch)\n    hash_reduce_left: int = self._hash_reduce_left\n    db_root: str = self._db_root\n    class_model: Any = self._class_model\n    # Run quantum loop\n    with concurrent.futures.ThreadPoolExecutor(self._max_workers) as executor:\n        for branch_number in branch_numbers:\n            future = executor.submit(\n                search_task_fn,\n                branch_number,\n                filter_fn,\n                hash_reduce_left,\n                db_root,\n                class_model,\n            )\n            docs = await future.result()\n            if docs is not None:\n                return docs[0]\n    return None\n</code></pre>"},{"location":"pages/mixins/keys/","title":"Keys","text":"<p>Methods for working with keys.</p>"},{"location":"pages/mixins/keys/#scruby.mixins.keys.Keys","title":"<code>Keys</code>","text":"<p>Methods for working with keys.</p> Source code in <code>src/scruby/mixins/keys.py</code> <pre><code>class Keys:\n    \"\"\"Methods for working with keys.\"\"\"\n\n    async def add_doc(self, doc: Any) -&gt; None:\n        \"\"\"Asynchronous method for adding document to collection.\n\n        Args:\n            doc (Any): Value of key. Type, derived from `ScrubyModel`.\n\n        Returns:\n            None.\n        \"\"\"\n        # Check if the Model matches the collection\n        if not isinstance(doc, self._class_model):\n            doc_class_name = doc.__class__.__name__\n            collection_name = self._class_model.__name__\n            msg = (\n                f\"(add_doc) Parameter `doc` =&gt; Model `{doc_class_name}` does not match collection `{collection_name}`!\"\n            )\n            logging.error(msg)\n            raise TypeError(msg)\n        # The path to cell of collection.\n        leaf_path, prepared_key = await self._get_leaf_path(doc.key)\n        # Init a `created_at` and `updated_at` fields\n        tz = ZoneInfo(\"UTC\")\n        doc.created_at = datetime.now(tz)\n        doc.updated_at = datetime.now(tz)\n        # Convert doc to json\n        doc_json: str = doc.model_dump_json()\n        # Write key-value to collection.\n        if await leaf_path.exists():\n            # Add new key.\n            data_json: bytes = await leaf_path.read_bytes()\n            data: dict = orjson.loads(data_json) or {}\n            try:\n                data[prepared_key]\n            except KeyError:\n                data[prepared_key] = doc_json\n                await leaf_path.write_bytes(orjson.dumps(data))\n            else:\n                err = KeyAlreadyExistsError()\n                logging.error(err.message)\n                raise err\n        else:\n            # Add new document to a blank leaf.\n            await leaf_path.write_bytes(orjson.dumps({prepared_key: doc_json}))\n        await self._counter_documents(1)\n\n    async def update_doc(self, doc: Any) -&gt; None:\n        \"\"\"Asynchronous method for updating document to collection.\n\n        Args:\n            doc (Any): Value of key. Type `ScrubyModel`.\n\n        Returns:\n            None.\n        \"\"\"\n        # Check if the Model matches the collection\n        if not isinstance(doc, self._class_model):\n            doc_class_name = doc.__class__.__name__\n            collection_name = self._class_model.__name__\n            msg = (\n                f\"(update_doc) Parameter `doc` =&gt; Model `{doc_class_name}` \"\n                f\"does not match collection `{collection_name}`!\"\n            )\n            logging.error(msg)\n            raise TypeError(msg)\n        # The path to cell of collection.\n        leaf_path, prepared_key = await self._get_leaf_path(doc.key)\n        # Update a `updated_at` field\n        doc.updated_at = datetime.now(ZoneInfo(\"UTC\"))\n        # Convert doc to json\n        doc_json: str = doc.model_dump_json()\n        # Update the existing key.\n        if await leaf_path.exists():\n            # Update the existing key.\n            data_json: bytes = await leaf_path.read_bytes()\n            data: dict = orjson.loads(data_json) or {}\n            try:\n                data[prepared_key]\n                data[prepared_key] = doc_json\n                await leaf_path.write_bytes(orjson.dumps(data))\n            except KeyError:\n                err = KeyNotExistsError()\n                logging.error(err.message)\n                raise err from None\n        else:\n            msg: str = f\"`update_doc` - The key `{doc.key}` is missing!\"\n            logging.error(msg)\n            raise KeyError(msg)\n\n    async def get_doc(self, key: str) -&gt; Any:\n        \"\"\"Asynchronous method for getting document from collection the by key.\n\n        Args:\n            key (str): Key name.\n\n        Returns:\n            Value of key or KeyError.\n        \"\"\"\n        # The path to the database cell.\n        leaf_path, prepared_key = await self._get_leaf_path(key)\n        # Get value of key.\n        if await leaf_path.exists():\n            data_json: bytes = await leaf_path.read_bytes()\n            data: dict = orjson.loads(data_json) or {}\n            obj: Any = self._class_model.model_validate_json(data[prepared_key])\n            return obj\n        msg: str = f\"`get_doc` - The key `{key}` is missing!\"\n        logging.error(msg)\n        raise KeyError(msg)\n\n    async def has_key(self, key: str) -&gt; bool:\n        \"\"\"Asynchronous method for checking presence of key in collection.\n\n        Args:\n            key (str): Key name.\n\n        Returns:\n            True, if the key is present.\n        \"\"\"\n        # Get path to cell of collection.\n        leaf_path, prepared_key = await self._get_leaf_path(key)\n        # Checking whether there is a key.\n        if await leaf_path.exists():\n            data_json: bytes = await leaf_path.read_bytes()\n            data: dict = orjson.loads(data_json) or {}\n            try:\n                data[prepared_key]\n                return True\n            except KeyError:\n                return False\n        return False\n\n    async def delete_doc(self, key: str) -&gt; None:\n        \"\"\"Asynchronous method for deleting document from collection the by key.\n\n        Args:\n            key (str): Key name.\n\n        Returns:\n            None.\n        \"\"\"\n        # The path to the database cell.\n        leaf_path, prepared_key = await self._get_leaf_path(key)\n        # Deleting key.\n        if await leaf_path.exists():\n            data_json: bytes = await leaf_path.read_bytes()\n            data: dict = orjson.loads(data_json) or {}\n            del data[prepared_key]\n            await leaf_path.write_bytes(orjson.dumps(data))\n            await self._counter_documents(-1)\n            return\n        msg: str = f\"`delete_doc` - The key `{key}` is missing!\"\n        logging.error(msg)\n        raise KeyError(msg)\n</code></pre>"},{"location":"pages/mixins/keys/#scruby.mixins.keys.Keys.add_doc","title":"<code>add_doc(doc)</code>  <code>async</code>","text":"<p>Asynchronous method for adding document to collection.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <code>Any</code> <p>Value of key. Type, derived from <code>ScrubyModel</code>.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None.</p> Source code in <code>src/scruby/mixins/keys.py</code> <pre><code>async def add_doc(self, doc: Any) -&gt; None:\n    \"\"\"Asynchronous method for adding document to collection.\n\n    Args:\n        doc (Any): Value of key. Type, derived from `ScrubyModel`.\n\n    Returns:\n        None.\n    \"\"\"\n    # Check if the Model matches the collection\n    if not isinstance(doc, self._class_model):\n        doc_class_name = doc.__class__.__name__\n        collection_name = self._class_model.__name__\n        msg = (\n            f\"(add_doc) Parameter `doc` =&gt; Model `{doc_class_name}` does not match collection `{collection_name}`!\"\n        )\n        logging.error(msg)\n        raise TypeError(msg)\n    # The path to cell of collection.\n    leaf_path, prepared_key = await self._get_leaf_path(doc.key)\n    # Init a `created_at` and `updated_at` fields\n    tz = ZoneInfo(\"UTC\")\n    doc.created_at = datetime.now(tz)\n    doc.updated_at = datetime.now(tz)\n    # Convert doc to json\n    doc_json: str = doc.model_dump_json()\n    # Write key-value to collection.\n    if await leaf_path.exists():\n        # Add new key.\n        data_json: bytes = await leaf_path.read_bytes()\n        data: dict = orjson.loads(data_json) or {}\n        try:\n            data[prepared_key]\n        except KeyError:\n            data[prepared_key] = doc_json\n            await leaf_path.write_bytes(orjson.dumps(data))\n        else:\n            err = KeyAlreadyExistsError()\n            logging.error(err.message)\n            raise err\n    else:\n        # Add new document to a blank leaf.\n        await leaf_path.write_bytes(orjson.dumps({prepared_key: doc_json}))\n    await self._counter_documents(1)\n</code></pre>"},{"location":"pages/mixins/keys/#scruby.mixins.keys.Keys.delete_doc","title":"<code>delete_doc(key)</code>  <code>async</code>","text":"<p>Asynchronous method for deleting document from collection the by key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Key name.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None.</p> Source code in <code>src/scruby/mixins/keys.py</code> <pre><code>async def delete_doc(self, key: str) -&gt; None:\n    \"\"\"Asynchronous method for deleting document from collection the by key.\n\n    Args:\n        key (str): Key name.\n\n    Returns:\n        None.\n    \"\"\"\n    # The path to the database cell.\n    leaf_path, prepared_key = await self._get_leaf_path(key)\n    # Deleting key.\n    if await leaf_path.exists():\n        data_json: bytes = await leaf_path.read_bytes()\n        data: dict = orjson.loads(data_json) or {}\n        del data[prepared_key]\n        await leaf_path.write_bytes(orjson.dumps(data))\n        await self._counter_documents(-1)\n        return\n    msg: str = f\"`delete_doc` - The key `{key}` is missing!\"\n    logging.error(msg)\n    raise KeyError(msg)\n</code></pre>"},{"location":"pages/mixins/keys/#scruby.mixins.keys.Keys.get_doc","title":"<code>get_doc(key)</code>  <code>async</code>","text":"<p>Asynchronous method for getting document from collection the by key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Key name.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>Value of key or KeyError.</p> Source code in <code>src/scruby/mixins/keys.py</code> <pre><code>async def get_doc(self, key: str) -&gt; Any:\n    \"\"\"Asynchronous method for getting document from collection the by key.\n\n    Args:\n        key (str): Key name.\n\n    Returns:\n        Value of key or KeyError.\n    \"\"\"\n    # The path to the database cell.\n    leaf_path, prepared_key = await self._get_leaf_path(key)\n    # Get value of key.\n    if await leaf_path.exists():\n        data_json: bytes = await leaf_path.read_bytes()\n        data: dict = orjson.loads(data_json) or {}\n        obj: Any = self._class_model.model_validate_json(data[prepared_key])\n        return obj\n    msg: str = f\"`get_doc` - The key `{key}` is missing!\"\n    logging.error(msg)\n    raise KeyError(msg)\n</code></pre>"},{"location":"pages/mixins/keys/#scruby.mixins.keys.Keys.has_key","title":"<code>has_key(key)</code>  <code>async</code>","text":"<p>Asynchronous method for checking presence of key in collection.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Key name.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True, if the key is present.</p> Source code in <code>src/scruby/mixins/keys.py</code> <pre><code>async def has_key(self, key: str) -&gt; bool:\n    \"\"\"Asynchronous method for checking presence of key in collection.\n\n    Args:\n        key (str): Key name.\n\n    Returns:\n        True, if the key is present.\n    \"\"\"\n    # Get path to cell of collection.\n    leaf_path, prepared_key = await self._get_leaf_path(key)\n    # Checking whether there is a key.\n    if await leaf_path.exists():\n        data_json: bytes = await leaf_path.read_bytes()\n        data: dict = orjson.loads(data_json) or {}\n        try:\n            data[prepared_key]\n            return True\n        except KeyError:\n            return False\n    return False\n</code></pre>"},{"location":"pages/mixins/keys/#scruby.mixins.keys.Keys.update_doc","title":"<code>update_doc(doc)</code>  <code>async</code>","text":"<p>Asynchronous method for updating document to collection.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <code>Any</code> <p>Value of key. Type <code>ScrubyModel</code>.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None.</p> Source code in <code>src/scruby/mixins/keys.py</code> <pre><code>async def update_doc(self, doc: Any) -&gt; None:\n    \"\"\"Asynchronous method for updating document to collection.\n\n    Args:\n        doc (Any): Value of key. Type `ScrubyModel`.\n\n    Returns:\n        None.\n    \"\"\"\n    # Check if the Model matches the collection\n    if not isinstance(doc, self._class_model):\n        doc_class_name = doc.__class__.__name__\n        collection_name = self._class_model.__name__\n        msg = (\n            f\"(update_doc) Parameter `doc` =&gt; Model `{doc_class_name}` \"\n            f\"does not match collection `{collection_name}`!\"\n        )\n        logging.error(msg)\n        raise TypeError(msg)\n    # The path to cell of collection.\n    leaf_path, prepared_key = await self._get_leaf_path(doc.key)\n    # Update a `updated_at` field\n    doc.updated_at = datetime.now(ZoneInfo(\"UTC\"))\n    # Convert doc to json\n    doc_json: str = doc.model_dump_json()\n    # Update the existing key.\n    if await leaf_path.exists():\n        # Update the existing key.\n        data_json: bytes = await leaf_path.read_bytes()\n        data: dict = orjson.loads(data_json) or {}\n        try:\n            data[prepared_key]\n            data[prepared_key] = doc_json\n            await leaf_path.write_bytes(orjson.dumps(data))\n        except KeyError:\n            err = KeyNotExistsError()\n            logging.error(err.message)\n            raise err from None\n    else:\n        msg: str = f\"`update_doc` - The key `{doc.key}` is missing!\"\n        logging.error(msg)\n        raise KeyError(msg)\n</code></pre>"},{"location":"pages/mixins/update/","title":"Update","text":"<p>Methods for updating documents.</p>"},{"location":"pages/mixins/update/#scruby.mixins.update.Update","title":"<code>Update</code>","text":"<p>Methods for updating documents.</p> Source code in <code>src/scruby/mixins/update.py</code> <pre><code>class Update:\n    \"\"\"Methods for updating documents.\"\"\"\n\n    @staticmethod\n    async def _task_update(\n        branch_number: int,\n        filter_fn: Callable,\n        hash_reduce_left: str,\n        db_root: str,\n        class_model: Any,\n        new_data: dict[str, Any],\n    ) -&gt; int:\n        \"\"\"Task for find documents.\n\n        This method is for internal use.\n\n        Returns:\n            The number of updated documents.\n        \"\"\"\n        branch_number_as_hash: str = f\"{branch_number:08x}\"[hash_reduce_left:]\n        separated_hash: str = \"/\".join(list(branch_number_as_hash))\n        leaf_path: Path = Path(\n            *(\n                db_root,\n                class_model.__name__,\n                separated_hash,\n                \"leaf.json\",\n            ),\n        )\n        counter: int = 0\n        if await leaf_path.exists():\n            data_json: bytes = await leaf_path.read_bytes()\n            data: dict[str, str] = orjson.loads(data_json) or {}\n            new_state: dict[str, str] = {}\n            for _, val in data.items():\n                doc = class_model.model_validate_json(val)\n                if filter_fn(doc):\n                    for key, value in new_data.items():\n                        doc.__dict__[key] = value\n                        new_state[key] = doc.model_dump_json()\n                    counter += 1\n            await leaf_path.write_bytes(orjson.dumps(new_state))\n        return counter\n\n    async def update_many(\n        self,\n        new_data: dict[str, Any],\n        filter_fn: Callable = lambda _: True,\n    ) -&gt; int:\n        \"\"\"Updates many documents matching the filter.\n\n        Attention:\n            - For a complex case, a custom task may be needed.\n            - See documentation on creating custom tasks.\n            - The search is based on the effect of a quantum loop.\n            - The search effectiveness depends on the number of processor threads.\n\n        Args:\n            filter_fn (Callable): A function that execute the conditions of filtering.\n            new_data (dict[str, Any]): New data for the fields that need to be updated.\n\n        Returns:\n            The number of updated documents.\n        \"\"\"\n        # Variable initialization\n        update_task_fn: Callable = self._task_update\n        branch_numbers: range = range(self._max_number_branch)\n        hash_reduce_left: int = self._hash_reduce_left\n        db_root: str = self._db_root\n        class_model: Any = self._class_model\n        counter: int = 0\n        # Run quantum loop\n        with concurrent.futures.ThreadPoolExecutor(self._max_workers) as executor:\n            for branch_number in branch_numbers:\n                future = executor.submit(\n                    update_task_fn,\n                    branch_number,\n                    filter_fn,\n                    hash_reduce_left,\n                    db_root,\n                    class_model,\n                    new_data,\n                )\n                counter += await future.result()\n        return counter\n</code></pre>"},{"location":"pages/mixins/update/#scruby.mixins.update.Update.update_many","title":"<code>update_many(new_data, filter_fn=lambda _: True)</code>  <code>async</code>","text":"<p>Updates many documents matching the filter.</p> Attention <ul> <li>For a complex case, a custom task may be needed.</li> <li>See documentation on creating custom tasks.</li> <li>The search is based on the effect of a quantum loop.</li> <li>The search effectiveness depends on the number of processor threads.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>filter_fn</code> <code>Callable</code> <p>A function that execute the conditions of filtering.</p> <code>lambda _: True</code> <code>new_data</code> <code>dict[str, Any]</code> <p>New data for the fields that need to be updated.</p> required <p>Returns:</p> Type Description <code>int</code> <p>The number of updated documents.</p> Source code in <code>src/scruby/mixins/update.py</code> <pre><code>async def update_many(\n    self,\n    new_data: dict[str, Any],\n    filter_fn: Callable = lambda _: True,\n) -&gt; int:\n    \"\"\"Updates many documents matching the filter.\n\n    Attention:\n        - For a complex case, a custom task may be needed.\n        - See documentation on creating custom tasks.\n        - The search is based on the effect of a quantum loop.\n        - The search effectiveness depends on the number of processor threads.\n\n    Args:\n        filter_fn (Callable): A function that execute the conditions of filtering.\n        new_data (dict[str, Any]): New data for the fields that need to be updated.\n\n    Returns:\n        The number of updated documents.\n    \"\"\"\n    # Variable initialization\n    update_task_fn: Callable = self._task_update\n    branch_numbers: range = range(self._max_number_branch)\n    hash_reduce_left: int = self._hash_reduce_left\n    db_root: str = self._db_root\n    class_model: Any = self._class_model\n    counter: int = 0\n    # Run quantum loop\n    with concurrent.futures.ThreadPoolExecutor(self._max_workers) as executor:\n        for branch_number in branch_numbers:\n            future = executor.submit(\n                update_task_fn,\n                branch_number,\n                filter_fn,\n                hash_reduce_left,\n                db_root,\n                class_model,\n                new_data,\n            )\n            counter += await future.result()\n    return counter\n</code></pre>"},{"location":"pages/usage/","title":"Usage","text":"<p>Examples of database use.</p>"},{"location":"pages/usage/aggregation/","title":"Aggregation classes","text":""},{"location":"pages/usage/aggregation/#average","title":"Average","text":"main.py<pre><code>\"\"\"Aggregation class for calculating the average value.\"\"\"\n\nimport anyio\nimport concurrent.futures\nfrom collections.abc import Callable\nfrom decimal import ROUND_HALF_EVEN\nfrom typing import Annotated, Any\n\nfrom pydantic import EmailStr, Field\nfrom pydantic_extra_types.phone_numbers import PhoneNumber, PhoneNumberValidator\n\nfrom scruby import Scruby, ScrubyModel, settings\nfrom scruby.aggregation import Average\n\nsettings.DB_ROOT = \"ScrubyDB\"  # By default = \"ScrubyDB\"\nsettings.HASH_REDUCE_LEFT = 6  # By default = 6\nsettings.MAX_WORKERS = None  # By default = None\n\n\nclass User(ScrubyModel):\n    \"\"\"User model.\"\"\"\n\n    first_name: str = Field(strict=True)\n    age: int = Field(strict=True)\n    email: EmailStr = Field(strict=True)\n    phone: Annotated[PhoneNumber, PhoneNumberValidator(number_format=\"E164\")] = Field(frozen=True)\n    # key is always at bottom\n    key: str = Field(\n        strict=True,\n        frozen=True,\n        default_factory=lambda data: data[\"phone\"],\n    )\n\n\nasync def task_calculate_average(\n    search_task_fn: Callable,\n    filter_fn: Callable,\n    branch_numbers: range,\n    hash_reduce_left: int,\n    db_root: str,\n    class_model: Any,\n    max_workers: int | None = None,\n) -&gt; float:\n    \"\"\"Custom task.\n\n    Calculate the average value.\n    \"\"\"\n    average_age = Average(\n        precision=\".00\",           # by default = .00\n        rounding=ROUND_HALF_EVEN,  # by default = ROUND_HALF_EVEN\n    )\n    # Run quantum loop\n    with concurrent.futures.ThreadPoolExecutor(max_workers) as executor:\n        for branch_number in branch_numbers:\n            future = executor.submit(\n                search_task_fn,\n                branch_number,\n                filter_fn,\n                hash_reduce_left,\n                db_root,\n                class_model,\n            )\n            docs = await future.result()\n            if docs is not None:\n                for doc in docs:\n                    average_age.set(doc.age)\n    return float(average_age.get())\n\n\nasync def main() -&gt; None:\n    \"\"\"Example.\"\"\"\n    # Get collection `User`.\n    user_coll = await Scruby.collection(User)\n\n    # Create users.\n    for num in range(1, 10):\n        user = User(\n            first_name=\"John\",\n            age=int(f\"{num * 10}\"),\n            email=f\"John_Smith_{num}@gmail.com\",\n            phone=f\"+44798612345{num}\",\n        )\n        await user_coll.add_doc(user)\n\n    result = await user_coll.run_custom_task(task_calculate_average)\n    print(result)  # =&gt; 50.0\n\n    # Full database deletion.\n    # Hint: The main purpose is tests.\n    Scruby.napalm()\n\n\nif __name__ == \"__main__\":\n    anyio.run(main)\n</code></pre>"},{"location":"pages/usage/aggregation/#counter","title":"Counter","text":"main.py<pre><code>\"\"\"Aggregation class for calculating sum of values.\"\"\"\n\nimport anyio\nimport concurrent.futures\nfrom collections.abc import Callable\nfrom typing import Annotated, Any\n\nfrom pydantic import EmailStr, Field\nfrom pydantic_extra_types.phone_numbers import PhoneNumber, PhoneNumberValidator\n\nfrom scruby import Scruby, ScrubyModel, settings\nfrom scruby.aggregation import Counter\n\nsettings.DB_ROOT = \"ScrubyDB\"  # By default = \"ScrubyDB\"\nsettings.HASH_REDUCE_LEFT = 6  # By default = 6\nsettings.MAX_WORKERS = None  # By default = None\n\n\nclass User(BaseModel):\n    \"\"\"User model.\"\"\"\n\n    first_name: str = Field(strict=True)\n    age: int = Field(strict=True)\n    email: EmailStr = Field(strict=True)\n    phone: Annotated[PhoneNumber, PhoneNumberValidator(number_format=\"E164\")] = Field(frozen=True)\n    # key is always at bottom\n    key: str = Field(\n        strict=True,\n        frozen=True,\n        default_factory=lambda data: data[\"phone\"],\n    )\n\n\nasync def task_counter(\n    search_task_fn: Callable,\n    filter_fn: Callable,\n    branch_numbers: range,\n    hash_reduce_left: int,\n    db_root: str,\n    class_model: Any,\n    max_workers: int | None = None,\n    limit_docs: int = 1000,  # custom parameter\n) -&gt; list[User]:\n    \"\"\"Custom task.\n\n    This task implements a counter of documents.\n    \"\"\"\n    counter = Counter(limit=limit_docs)  # `limit` by default = 1000\n    users: list[User] = []\n    # Run quantum loop\n    with concurrent.futures.ThreadPoolExecutor(max_workers) as executor:\n        for branch_number in branch_numbers:\n            future = executor.submit(\n                search_task_fn,\n                branch_number,\n                filter_fn,\n                hash_reduce_left,\n                db_root,\n                class_model,\n            )\n            docs = await future.result()\n            if docs is not None:\n                for doc in docs:\n                    if counter.check():\n                        # [:limit_docs] - Control overflow in a multithreaded environment.\n                        return users[:limit_docs]\n                    users.append(doc)\n                    counter.next()\n    return users\n\n\nasync def main() -&gt; None:\n    \"\"\"Example.\"\"\"\n    # Get collection `User`.\n    user_coll = await Scruby.collection(User)\n\n    # Create users.\n    for num in range(1, 10):\n        user = User(\n            first_name=\"John\",\n            age=int(f\"{num * 10}\"),\n            email=f\"John_Smith_{num}@gmail.com\",\n            phone=f\"+44798612345{num}\",\n        )\n        await user_coll.add_doc(user)\n\n    result = await user_coll.run_custom_task(\n        custom_task_fn=task_counter,\n        limit_docs=5,  # custom parameter\n    )\n    print(len(result))  # =&gt; 5\n\n    # Full database deletion.\n    # Hint: The main purpose is tests.\n    Scruby.napalm()\n\n\nif __name__ == \"__main__\":\n    anyio.run(main)\n</code></pre>"},{"location":"pages/usage/aggregation/#max","title":"Max","text":"main.py<pre><code>\"\"\"Aggregation class for calculating the maximum value.\"\"\"\n\nimport anyio\nimport concurrent.futures\nfrom collections.abc import Callable\nfrom typing import Annotated, Any\n\nfrom pydantic import EmailStr, Field\nfrom pydantic_extra_types.phone_numbers import PhoneNumber, PhoneNumberValidator\n\nfrom scruby import Scruby, ScrubyModel, settings\nfrom scruby.aggregation import Max\n\nsettings.DB_ROOT = \"ScrubyDB\"  # By default = \"ScrubyDB\"\nsettings.HASH_REDUCE_LEFT = 6  # By default = 6\nsettings.MAX_WORKERS = None  # By default = None\n\n\nclass User(ScrubyModel):\n    \"\"\"User model.\"\"\"\n\n    first_name: str = Field(strict=True)\n    age: int = Field(strict=True)\n    email: EmailStr = Field(strict=True)\n    phone: Annotated[PhoneNumber, PhoneNumberValidator(number_format=\"E164\")] = Field(frozen=True)\n    # key is always at bottom\n    key: str = Field(\n        strict=True,\n        frozen=True,\n        default_factory=lambda data: data[\"phone\"],\n    )\n\n\nasync def task_calculate_max(\n    search_task_fn: Callable,\n    filter_fn: Callable,\n    branch_numbers: range,\n    hash_reduce_left: int,\n    db_root: str,\n    class_model: Any,\n    max_workers: int | None = None,\n) -&gt; int:\n    \"\"\"Custom task.\n\n    Calculate the max value.\n    \"\"\"\n    max_age = Max()\n    # Run quantum loop\n    with concurrent.futures.ThreadPoolExecutor(max_workers) as executor:\n        for branch_number in branch_numbers:\n            future = executor.submit(\n                search_task_fn,\n                branch_number,\n                filter_fn,\n                hash_reduce_left,\n                db_root,\n                class_model,\n            )\n            docs = await future.result()\n            if docs is not None:\n                for doc in docs:\n                    max_age.set(doc.age)\n    return max_age.get()\n\n\nasync def main() -&gt; None:\n    \"\"\"Example.\"\"\"\n    # Get collection `User`.\n    user_coll = await Scruby.collection(User)\n\n    # Create users.\n    for num in range(1, 10):\n        user = User(\n            first_name=\"John\",\n            age=int(f\"{num * 10}\"),\n            email=f\"John_Smith_{num}@gmail.com\",\n            phone=f\"+44798612345{num}\",\n        )\n        await user_coll.add_doc(user)\n\n    result = await user_coll.run_custom_task(task_calculate_max)\n    print(result)  # =&gt; 90.0\n\n    # Full database deletion.\n    # Hint: The main purpose is tests.\n    Scruby.napalm()\n\n\nif __name__ == \"__main__\":\n    anyio.run(main)\n</code></pre>"},{"location":"pages/usage/aggregation/#min","title":"Min","text":"main.py<pre><code>\"\"\"Aggregation class for calculating the minimum value.\"\"\"\n\nimport anyio\nimport concurrent.futures\nfrom collections.abc import Callable\nfrom typing import Annotated, Any\n\nfrom pydantic import EmailStr, Field\nfrom pydantic_extra_types.phone_numbers import PhoneNumber, PhoneNumberValidator\n\nfrom scruby import Scruby, ScrubyModel, settings\nfrom scruby.aggregation import Min\n\nsettings.DB_ROOT = \"ScrubyDB\"  # By default = \"ScrubyDB\"\nsettings.HASH_REDUCE_LEFT = 6  # By default = 6\nsettings.MAX_WORKERS = None  # By default = None\n\n\nclass User(ScrubyModel):\n    \"\"\"User model.\"\"\"\n\n    first_name: str = Field(strict=True)\n    age: int = Field(strict=True)\n    email: EmailStr = Field(strict=True)\n    phone: Annotated[PhoneNumber, PhoneNumberValidator(number_format=\"E164\")] = Field(frozen=True)\n    # key is always at bottom\n    key: str = Field(\n        strict=True,\n        frozen=True,\n        default_factory=lambda data: data[\"phone\"],\n    )\n\n\nasync def task_calculate_min(\n    search_task_fn: Callable,\n    filter_fn: Callable,\n    branch_numbers: range,\n    hash_reduce_left: int,\n    db_root: str,\n    class_model: Any,\n    max_workers: int | None = None,\n) -&gt; int:\n    \"\"\"Custom task.\n\n    Calculate the min value.\n    \"\"\"\n    min_age = Min()\n    # Run quantum loop\n    with concurrent.futures.ThreadPoolExecutor(max_workers) as executor:\n        for branch_number in branch_numbers:\n            future = executor.submit(\n                search_task_fn,\n                branch_number,\n                filter_fn,\n                hash_reduce_left,\n                db_root,\n                class_model,\n            )\n            docs = await future.result()\n            if docs is not None:\n                for doc in docs:\n                    min_age.set(doc.age)\n    return min_age.get()\n\n\nasync def main() -&gt; None:\n    \"\"\"Example.\"\"\"\n    # Get collection `User`.\n    user_coll = await Scruby.collection(User)\n\n    # Create users.\n    for num in range(1, 10):\n        user = User(\n            first_name=\"John\",\n            age=int(f\"{num * 10}\"),\n            email=f\"John_Smith_{num}@gmail.com\",\n            phone=f\"+44798612345{num}\",\n        )\n        await user_coll.add_doc(user)\n\n    result = await user_coll.run_custom_task(task_calculate_min)\n    print(result)  # =&gt; 10.0\n\n    # Full database deletion.\n    # Hint: The main purpose is tests.\n    Scruby.napalm()\n\n\nif __name__ == \"__main__\":\n    anyio.run(main)\n</code></pre>"},{"location":"pages/usage/aggregation/#sum","title":"Sum","text":"main.py<pre><code>\"\"\"Aggregation class for calculating sum of values.\"\"\"\n\nimport anyio\nimport concurrent.futures\nfrom collections.abc import Callable\nfrom typing import Annotated, Any\n\nfrom pydantic import EmailStr, Field\nfrom pydantic_extra_types.phone_numbers import PhoneNumber, PhoneNumberValidator\n\nfrom scruby import Scruby, ScrubyModel, settings\nfrom scruby.aggregation import Sum\n\nsettings.DB_ROOT = \"ScrubyDB\"  # By default = \"ScrubyDB\"\nsettings.HASH_REDUCE_LEFT = 6  # By default = 6\nsettings.MAX_WORKERS = None  # By default = None\n\n\nclass User(ScrubyModel):\n    \"\"\"User model.\"\"\"\n\n    first_name: str = Field(strict=True)\n    age: int = Field(strict=True)\n    email: EmailStr = Field(strict=True)\n    phone: Annotated[PhoneNumber, PhoneNumberValidator(number_format=\"E164\")] = Field(frozen=True)\n    # key is always at bottom\n    key: str = Field(\n        strict=True,\n        frozen=True,\n        default_factory=lambda data: data[\"phone\"],\n    )\n\n\nasync def task_calculate_sum(\n    search_task_fn: Callable,\n    filter_fn: Callable,\n    branch_numbers: range,\n    hash_reduce_left: int,\n    db_root: str,\n    class_model: Any,\n    max_workers: int | None = None,\n) -&gt; int:\n    \"\"\"Custom task.\n\n    Calculate the sum of values.\n    \"\"\"\n    sum_age = Sum()\n    # Run quantum loop\n    with concurrent.futures.ThreadPoolExecutor(max_workers) as executor:\n        for branch_number in branch_numbers:\n            future = executor.submit(\n                search_task_fn,\n                branch_number,\n                filter_fn,\n                hash_reduce_left,\n                db_root,\n                class_model,\n            )\n            docs = await future.result()\n            if docs is not None:\n                for doc in docs:\n                    sum_age.set(doc.age)\n    return int(sum_age.get())\n\n\nasync def main() -&gt; None:\n    \"\"\"Example.\"\"\"\n    # Get collection `User`.\n    user_coll = await Scruby.collection(User)\n\n    # Create users.\n    for num in range(1, 10):\n        user = User(\n            first_name=\"John\",\n            age=int(f\"{num * 10}\"),\n            email=f\"John_Smith_{num}@gmail.com\",\n            phone=f\"+44798612345{num}\",\n        )\n        await user_coll.add_doc(user)\n\n    result = await user_coll.run_custom_task(task_calculate_sum)\n    print(result)  # =&gt; 450.0\n\n    # Full database deletion.\n    # Hint: The main purpose is tests.\n    Scruby.napalm()\n\n\nif __name__ == \"__main__\":\n    anyio.run(main)\n</code></pre>"},{"location":"pages/usage/count_documents/","title":"Count documents","text":""},{"location":"pages/usage/count_documents/#get-an-estimate-of-number-of-documents-using-collection-metadata","title":"Get an estimate of number of documents using collection metadata","text":"main.py<pre><code>\"\"\"Get an estimate of the number of documents in this collection using collection metadata.\"\"\"\n\nimport anyio\nfrom datetime import datetime\nfrom zoneinfo import ZoneInfo\nfrom typing import Annotated\nfrom pydantic import EmailStr\nfrom pydantic_extra_types.phone_numbers import PhoneNumber, PhoneNumberValidator\nfrom scruby import Scruby, ScrubyModel, settings\n\nsettings.DB_ROOT = \"ScrubyDB\"  # By default = \"ScrubyDB\"\nsettings.HASH_REDUCE_LEFT = 6  # By default = 6\nsettings.MAX_WORKERS = None  # By default = None\n\n\nclass User(ScrubyModel):\n    \"\"\"Model of User.\"\"\"\n    first_name: str\n    last_name: str\n    birthday: datetime\n    email: EmailStr\n    phone: Annotated[PhoneNumber, PhoneNumberValidator(number_format=\"E164\")]\n    # key is always at bottom\n    key: str = Field(\n        strict=True,\n        frozen=True,\n        default_factory=lambda data: data[\"phone\"],\n    )\n\n\nasync def main() -&gt; None:\n    \"\"\"Example.\"\"\"\n    # Get collection `User`.\n    user_coll = await Scruby.collection(User)\n\n    # Create user.\n    user = User(\n        first_name=\"John\",\n        last_name=\"Smith\",\n        birthday=datetime(1970, 1, 1, tzinfo=ZoneInfo(\"UTC\")),\n        email=\"John_Smith@gmail.com\",\n        phone=\"+447986123456\",\n    )\n\n    print(await user_coll.estimated_document_count())  # =&gt; 0\n\n    # Add user to collection.\n    await user_coll.add_doc(user)\n    print(await user_coll.estimated_document_count())  # =&gt; 1\n\n    # Delete user from collection.\n    await user_coll.delete_doc(\"+447986123456\")\n    print(await user_coll.estimated_document_count())  # =&gt; 0\n\n    # Full database deletion.\n    # Hint: The main purpose is tests.\n    Scruby.napalm()\n\n\nif __name__ == \"__main__\":\n    anyio.run(main)\n</code></pre>"},{"location":"pages/usage/count_documents/#count-number-of-documents-in-collection","title":"Count number of documents in collection","text":"main.py<pre><code>\"\"\"Count the number of documents a matching the filter in this collection.\"\"\"\n\nimport anyio\nfrom datetime import datetime\nfrom zoneinfo import ZoneInfo\nfrom typing import Annotated\nfrom pydantic import EmailStr, Field\nfrom pydantic_extra_types.phone_numbers import PhoneNumber, PhoneNumberValidator\nfrom scruby import Scruby, ScrubyModel, settings\n\nsettings.DB_ROOT = \"ScrubyDB\"  # By default = \"ScrubyDB\"\nsettings.HASH_REDUCE_LEFT = 6  # By default = 6\nsettings.MAX_WORKERS = None  # By default = None\n\n\nclass User(ScrubyModel):\n    \"\"\"User model.\"\"\"\n\n    first_name: str = Field(strict=True)\n    last_name: str = Field(strict=True)\n    birthday: datetime = Field(strict=True)\n    email: EmailStr = Field(strict=True)\n    phone: Annotated[PhoneNumber, PhoneNumberValidator(number_format=\"E164\")] = Field(frozen=True)\n    # key is always at bottom\n    key: str = Field(\n        strict=True,\n        frozen=True,\n        default_factory=lambda data: data[\"phone\"],\n    )\n\n\nasync def main() -&gt; None:\n    \"\"\"Example.\"\"\"\n    # Get collection `User`.\n    user_coll = await Scruby.collection(User)\n\n    # Create users.\n    for num in range(1, 10):\n        user = User(\n            first_name=\"John\",\n            last_name=\"Smith\",\n            birthday=datetime(1970, 1, num, tzinfo=ZoneInfo(\"UTC\")),\n            email=f\"John_Smith_{num}@gmail.com\",\n            phone=f\"+44798612345{num}\",\n        )\n        await db.set_key(user.key, user)\n\n    result: int = await user_coll.count_documents(\n        filter_fn=lambda doc: doc.email == \"John_Smith_5@gmail.com\" or doc.email == \"John_Smith_8@gmail.com\",\n    )\n    print(result:)  # =&gt; 2\n\n    # Full database deletion.\n    # Hint: The main purpose is tests.\n    Scruby.napalm()\n\n\nif __name__ == \"__main__\":\n    anyio.run(main)\n</code></pre>"},{"location":"pages/usage/custom_task/","title":"Custom task","text":""},{"location":"pages/usage/custom_task/#custom-task","title":"Custom task","text":"main.py<pre><code>\"\"\"Running custom task.\n\nThis method running a task created on the basis of a quantum loop.\nEffectiveness running task depends on the number of processor threads.\n\"\"\"\n\nimport anyio\nfrom datetime import datetime\nfrom zoneinfo import ZoneInfo\nimport concurrent.futures\nfrom typing import Annotated, Any\nfrom collections.abc import Callable\nfrom pydantic import EmailStr, Field\nfrom pydantic_extra_types.phone_numbers import PhoneNumber, PhoneNumberValidator\nfrom scruby import Scruby, ScrubyModel, settings\nfrom scruby.aggregation import Counter\n\nsettings.DB_ROOT = \"ScrubyDB\"  # By default = \"ScrubyDB\"\nsettings.HASH_REDUCE_LEFT = 6  # By default = 6\nsettings.MAX_WORKERS = None  # By default = None\n\n\nclass User(ScrubyModel):\n    \"\"\"User model.\"\"\"\n\n    first_name: str = Field(strict=True)\n    last_name: str = Field(strict=True)\n    birthday: datetime = Field(strict=True)\n    email: EmailStr = Field(strict=True)\n    phone: Annotated[PhoneNumber, PhoneNumberValidator(number_format=\"E164\")] = Field(frozen=True)\n    # key is always at bottom\n    key: str = Field(\n        strict=True,\n        frozen=True,\n        default_factory=lambda data: data[\"phone\"],\n    )\n\n\nasync def task_counter(\n    search_task_fn: Callable,\n    filter_fn: Callable,\n    branch_numbers: range,\n    hash_reduce_left: int,\n    db_root: str,\n    class_model: Any,\n    max_workers: int | None = None,\n    limit_docs: int = 1000,  # custom parameter\n) -&gt; list[User]:\n    \"\"\"Custom task.\n\n    This task implements a counter of documents.\n    \"\"\"\n    counter = Counter(limit=limit_docs)  # `limit` by default = 1000\n    users: list[User] = []\n    # Run quantum loop\n    with concurrent.futures.ThreadPoolExecutor(max_workers) as executor:\n        for branch_number in branch_numbers:\n            future = executor.submit(\n                search_task_fn,\n                branch_number,\n                filter_fn,\n                hash_reduce_left,\n                db_root,\n                class_model,\n            )\n            docs = await future.result()\n            if docs is not None:\n                for doc in docs:\n                    if counter.check():\n                        # [:limit_docs] - Control overflow in a multithreaded environment.\n                        return users[:limit_docs]\n                    if filter_fn(doc):\n                        users.append(doc)\n                        counter.next()\n    return users\n\n\nasync def main() -&gt; None:\n    \"\"\"Example.\"\"\"\n    # Get collection `User`.\n    user_coll = await Scruby.collection(User)\n\n    # Create users.\n    for num in range(1, 10):\n        user = User(\n            first_name=\"John\",\n            last_name=\"Smith\",\n            birthday=datetime(1970, 1, num, tzinfo=ZoneInfo(\"UTC\")),\n            email=f\"John_Smith_{num}@gmail.com\",\n            phone=f\"+44798612345{num}\",\n        )\n        await user_coll.add_doc(user)\n\n    result = await user_coll.run_custom_task(\n        custom_task_fn=task_counter,\n        filter_fn=lambda doc: doc.first_name == \"John\",\n        limit_docs=5,  # custom parameter\n    )\n    print(result)  # =&gt; 9\n\n    # Full database deletion.\n    # Hint: The main purpose is tests.\n    Scruby.napalm()\n\n\nif __name__ == \"__main__\":\n    anyio.run(main)\n</code></pre>"},{"location":"pages/usage/delete_collection/","title":"Delete collection","text":""},{"location":"pages/usage/delete_collection/#delete-collection","title":"Delete Collection","text":"main.py<pre><code>\"\"\"Delete collection.\"\"\"\n\nimport anyio\nfrom datetime import datetime\nfrom typing import Annotated\nfrom pydantic import EmailStr, Field\nfrom pydantic_extra_types.phone_numbers import PhoneNumber, PhoneNumberValidator\nfrom scruby import Scruby, ScrubyModel, settings\n\nsettings.DB_ROOT = \"ScrubyDB\"  # By default = \"ScrubyDB\"\nsettings.HASH_REDUCE_LEFT = 6  # By default = 6\nsettings.MAX_WORKERS = None  # By default = None\n\n\nclass User(ScrubyModel):\n    \"\"\"User model.\"\"\"\n\n    first_name: str = Field(strict=True)\n    last_name: str = Field(strict=True)\n    birthday: datetime = Field(strict=True)\n    email: EmailStr = Field(strict=True)\n    phone: Annotated[PhoneNumber, PhoneNumberValidator(number_format=\"E164\")] = Field(frozen=True)\n    # key is always at bottom\n    key: str = Field(\n        strict=True,\n        frozen=True,\n        default_factory=lambda data: data[\"phone\"],\n    )\n\n\nasync def main() -&gt; None:\n    \"\"\"Example.\"\"\"\n    # Get collection `User`.\n    user_coll = await Scruby.collection(User)\n\n    collection_list = await Scruby.collection_list()\n    print(ucollection_list)  # [\"User\"]\n\n    await Scruby.delete_collection(\"User\")\n\n    collection_list = await Scruby.collection_list()\n    print(ucollection_list)  # []\n\n    # Full database deletion.\n    # Hint: The main purpose is tests.\n    Scruby.napalm()\n\n\nif __name__ == \"__main__\":\n    anyio.run(main)\n</code></pre>"},{"location":"pages/usage/delete_documents/","title":"Delete documents","text":""},{"location":"pages/usage/delete_documents/#find-a-single-document-and-delete","title":"Find a single document and delete","text":"main.py<pre><code>\"\"\"Find a single document, matching the filter and delete it.\n\nThe search is based on the effect of a quantum loop.\nThe search effectiveness depends on the number of processor threads.\n\"\"\"\n\nimport anyio\nfrom datetime import datetime\nfrom zoneinfo import ZoneInfo\nfrom typing import Annotated\nfrom pydantic import EmailStr, Field\nfrom pydantic_extra_types.phone_numbers import PhoneNumber, PhoneNumberValidator\nfrom scruby import Scruby, ScrubyModel, settings\n\nsettings.DB_ROOT = \"ScrubyDB\"  # By default = \"ScrubyDB\"\nsettings.HASH_REDUCE_LEFT = 6  # By default = 6\nsettings.MAX_WORKERS = None  # By default = None\n\n\nclass User(ScrubyModel):\n    \"\"\"User model.\"\"\"\n\n    first_name: str = Field(strict=True)\n    last_name: str = Field(strict=True)\n    birthday: datetime = Field(strict=True)\n    email: EmailStr = Field(strict=True)\n    phone: Annotated[PhoneNumber, PhoneNumberValidator(number_format=\"E164\")] = Field(frozen=True)\n    # key is always at bottom\n    key: str = Field(\n        strict=True,\n        frozen=True,\n        default_factory=lambda data: data[\"phone\"],\n    )\n\n\nasync def main() -&gt; None:\n    \"\"\"Example.\"\"\"\n    # Get collection `User`.\n    user_coll = await Scruby.collection(User)\n\n    # Create user.\n    user = User(\n        first_name=\"John\",\n        last_name=\"Smith\",\n        birthday=datetime(1970, 1, 1),\n        email=\"John_Smith@gmail.com\",\n        phone=\"+447986123456\",\n    )\n\n    # Add user to collection.\n    await user_coll.add_doc(user)\n\n    # Find user by email.\n    user_details: User | None = user_coll.find_one(\n        filter_fn=lambda doc: doc.phone == \"+447986123456\",\n    )\n    # Delete user from collection.\n    if user_details is not None:\n        await user_coll.delete_doc(user_details.key)\n\n    # Full database deletion.\n    # Hint: The main purpose is tests.\n    Scruby.napalm()\n\n\nif __name__ == \"__main__\":\n    anyio.run(main)\n</code></pre>"},{"location":"pages/usage/delete_documents/#find-one-or-more-documents-and-deletes","title":"Find one or more documents and deletes","text":"main.py<pre><code>\"\"\"Delete one or more documents matching the filter.\n\nThe search is based on the effect of a quantum loop.\nThe search effectiveness depends on the number of processor threads.\n\"\"\"\n\nimport anyio\nfrom datetime import datetime\nfrom zoneinfo import ZoneInfo\nfrom typing import Annotated\nfrom pydantic import EmailStr, Field\nfrom pydantic_extra_types.phone_numbers import PhoneNumber, PhoneNumberValidator\nfrom scruby import Scruby, ScrubyModel, settings\n\nsettings.DB_ROOT = \"ScrubyDB\"  # By default = \"ScrubyDB\"\nsettings.HASH_REDUCE_LEFT = 6  # By default = 6\nsettings.MAX_WORKERS = None  # By default = None\n\n\nclass User(ScrubyModel):\n    \"\"\"User model.\"\"\"\n\n    first_name: str = Field(strict=True)\n    last_name: str = Field(strict=True)\n    birthday: datetime = Field(strict=True)\n    email: EmailStr = Field(strict=True)\n    phone: Annotated[PhoneNumber, PhoneNumberValidator(number_format=\"E164\")] = Field(frozen=True)\n    # key is always at bottom\n    key: str = Field(\n        strict=True,\n        frozen=True,\n        default_factory=lambda data: data[\"phone\"],\n    )\n\n\nasync def main() -&gt; None:\n    \"\"\"Example.\"\"\"\n    # Get collection `User`.\n    user_coll = await Scruby.collection(User)\n\n    # Create users.\n    for num in range(1, 10):\n        user = User(\n            first_name=\"John\",\n            last_name=\"Smith\",\n            birthday=datetime(1970, 1, num, tzinfo=ZoneInfo(\"UTC\")),\n            email=f\"John_Smith_{num}@gmail.com\",\n            phone=f\"+44798612345{num}\",\n        )\n        await user_coll.add_doc(user)\n\n    amount_of_deleted: int = await user_coll.delete_many(\n        filter_fn=lambda doc: doc.email == \"John_Smith_5@gmail.com\" or doc.email == \"John_Smith_8@gmail.com\",\n    )\n    print(amount_of_deleted)  # =&gt; 2\n\n    # Full database deletion.\n    # Hint: The main purpose is tests.\n    Scruby.napalm()\n\n\nif __name__ == \"__main__\":\n    anyio.run(main)\n</code></pre>"},{"location":"pages/usage/find_many_documents/","title":"Find many documents","text":""},{"location":"pages/usage/find_many_documents/#find-many-documents-matching-the-filter","title":"Find many documents matching the filter","text":"main.py<pre><code>\"\"\"Find many documents matching the filter.\n\nThe search is based on the effect of a quantum loop.\nThe search effectiveness depends on the number of processor threads.\n\"\"\"\n\nimport anyio\nfrom typing import Annotated\nfrom pydantic import Field\nfrom scruby import Scruby, ScrubyModel, settings\nfrom pprint import pprint as pp\n\nsettings.DB_ROOT = \"ScrubyDB\"  # By default = \"ScrubyDB\"\nsettings.HASH_REDUCE_LEFT = 6  # By default = 6\nsettings.MAX_WORKERS = None  # By default = None\n\n\nclass Car(ScrubyModel):\n    \"\"\"Car model.\"\"\"\n    brand: str = Field(strict=True, frozen=True)\n    model: str = Field(strict=True, frozen=True)\n    year: int = Field(strict=True)\n    power_reserve: int = Field(strict=True)\n    # key is always at bottom\n    key: str = Field(\n        strict=True,\n        frozen=True,\n        default_factory=lambda data: f\"{data['brand']}:{data['model']}\",\n    )\n\n\nasync def main() -&gt; None:\n    \"\"\"Example.\"\"\"\n    # Get collection `Car`.\n    car_coll = await Scruby.collection(Car)\n\n    # Create cars.\n    for num in range(1, 10):\n        car = Car(\n            brand=\"Mazda\",\n            model=f\"EZ-6 {num}\",\n            year=2025,\n            power_reserve=600,\n        )\n        await car_coll.add_doc(car)\n\n    # Find cars by brand and year.\n    car_list: list[Car] | None = await car_coll.find_many(\n        filter_fn=lambda doc: doc.brand == \"Mazda\" and doc.year == 2025,\n    )\n    if car_list is not None:\n        pp(car_list)\n    else:\n        print(\"No cars!\")\n\n    # Find all cars.\n    car_list: list[Car] | None = await car_coll.find_many()\n    if car_list is not None:\n        pp(car_list)\n    else:\n        print(\"No cars!\")\n\n    # For pagination output.\n    car_list: list[Car] | None = await car_coll.find_many(\n        filter_fn=lambda doc: doc.brand == \"Mazda\",\n        limit_docs=5,\n        page_number=2,\n    )\n    if car_list is not None:\n        pp(car_list)\n    else:\n        print(\"No cars!\")\n\n    # Full database deletion.\n    # Hint: The main purpose is tests.\n    Scruby.napalm()\n\n\nif __name__ == \"__main__\":\n    anyio.run(main)\n</code></pre>"},{"location":"pages/usage/find_one_document/","title":"Find one document","text":""},{"location":"pages/usage/find_one_document/#find-one-document-matching-the-filter","title":"Find one document matching the filter","text":"main.py<pre><code>\"\"\"Find one document matching the filter.\n\nThe search is based on the effect of a quantum loop.\nThe search effectiveness depends on the number of processor threads.\n\"\"\"\n\nimport anyio\nfrom typing import Annotated\nfrom pydantic import Field\nfrom scruby import Scruby, ScrubyModel, settings\nfrom pprint import pprint as pp\n\nsettings.DB_ROOT = \"ScrubyDB\"  # By default = \"ScrubyDB\"\nsettings.HASH_REDUCE_LEFT = 6  # By default = 6\nsettings.MAX_WORKERS = None  # By default = None\n\n\nclass Phone(ScrubyModel):\n    \"\"\"Phone model.\"\"\"\n    brand: str = Field(strict=True, frozen=True)\n    model: str = Field(strict=True, frozen=True)\n    screen_diagonal: float = Field(strict=True)\n    matrix_type: str = Field(strict=True)\n    # key is always at bottom\n    key: str = Field(\n        strict=True,\n        frozen=True,\n        default_factory=lambda data: f\"{data['brand']}:{data['model']}\",\n    )\n\n\nasync def main() -&gt; None:\n    \"\"\"Example.\"\"\"\n    # Get collection `Phone`.\n    phone_coll = await Scruby.collection(Phone)\n\n    # Create phone.\n    phone = Phone(\n        brand=\"Samsung\",\n        model=\"Galaxy A26\",\n        screen_diagonal=6.7,\n        matrix_type=\"Super AMOLED\",\n    )\n\n    # Add phone to collection.\n    await phone_coll.add_doc(phone)\n\n    # Find phone by brand.\n    phone_details: Phone | None = await phone_coll.find_one(\n        filter_fn=lambda doc: doc.brand == \"Samsung\",\n    )\n    if phone_details is not None:\n        pp(phone_details)\n    else:\n        print(\"No Phone!\")\n\n    # Find phone by model.\n    phone_details: Phone | None = await phone_coll.find_one(\n        filter_fn=lambda doc: doc.model == \"Galaxy A26\",\n    )\n    if phone_details is not None:\n        pp(phone_details)\n    else:\n        print(\"No Phone!\")\n\n    # Full database deletion.\n    # Hint: The main purpose is tests.\n    Scruby.napalm()\n\n\nif __name__ == \"__main__\":\n    anyio.run(main)\n</code></pre>"},{"location":"pages/usage/get_collection_list/","title":"Get collection list","text":""},{"location":"pages/usage/get_collection_list/#get-collection-list","title":"Get collection list","text":"main.py<pre><code>\"\"\"Get collection list.\"\"\"\n\nimport anyio\nfrom datetime import datetime\nfrom typing import Annotated\nfrom pydantic import EmailStr, Field\nfrom pydantic_extra_types.phone_numbers import PhoneNumber, PhoneNumberValidator\nfrom scruby import Scruby, ScrubyModel, settings\n\nsettings.DB_ROOT = \"ScrubyDB\"  # By default = \"ScrubyDB\"\nsettings.HASH_REDUCE_LEFT = 6  # By default = 6\nsettings.MAX_WORKERS = None  # By default = None\n\n\nclass User(ScrubyModel):\n    \"\"\"User model.\"\"\"\n\n    first_name: str = Field(strict=True)\n    last_name: str = Field(strict=True)\n    birthday: datetime = Field(strict=True)\n    email: EmailStr = Field(strict=True)\n    phone: Annotated[PhoneNumber, PhoneNumberValidator(number_format=\"E164\")] = Field(frozen=True)\n    # key is always at bottom\n    key: str = Field(\n        strict=True,\n        frozen=True,\n        default_factory=lambda data: data[\"phone\"],\n    )\n\n\nasync def main() -&gt; None:\n    \"\"\"Example.\"\"\"\n    # Get collection `User`.\n    user_coll = await Scruby.collection(User)\n\n    collection_list = await Scruby.collection_list()\n    print(ucollection_list)  # [\"User\"]\n\n    # Full database deletion.\n    # Hint: The main purpose is tests.\n    Scruby.napalm()\n\n\nif __name__ == \"__main__\":\n    anyio.run(main)\n</code></pre>"},{"location":"pages/usage/get_collection_name/","title":"Get collection name","text":""},{"location":"pages/usage/get_collection_name/#get-collection-name","title":"Get collection name","text":"main.py<pre><code>\"\"\"Get collection name.\"\"\"\n\nimport anyio\nfrom datetime import datetime\nfrom zoneinfo import ZoneInfo\nfrom typing import Annotated\nfrom pydantic import EmailStr, Field\nfrom pydantic_extra_types.phone_numbers import PhoneNumber, PhoneNumberValidator\nfrom scruby import Scruby, ScrubyModel, settings\n\nsettings.DB_ROOT = \"ScrubyDB\"  # By default = \"ScrubyDB\"\nsettings.HASH_REDUCE_LEFT = 6  # By default = 6\nsettings.MAX_WORKERS = None  # By default = None\n\n\nclass User(ScrubyModel):\n    \"\"\"User model.\"\"\"\n\n    first_name: str = Field(strict=True)\n    last_name: str = Field(strict=True)\n    birthday: datetime = Field(strict=True)\n    email: EmailStr = Field(strict=True)\n    phone: Annotated[PhoneNumber, PhoneNumberValidator(number_format=\"E164\")] = Field(frozen=True)\n    # key is always at bottom\n    key: str = Field(\n        strict=True,\n        frozen=True,\n        default_factory=lambda data: data[\"phone\"],\n    )\n\n\nasync def main() -&gt; None:\n    \"\"\"Example.\"\"\"\n    # Get collection `User`.\n    user_coll = await Scruby.collection(User)\n\n    print(user_coll.collection_name())  # \"User\"\n\n    # Full database deletion.\n    # Hint: The main purpose is tests.\n    Scruby.napalm()\n\n\nif __name__ == \"__main__\":\n    anyio.run(main)\n</code></pre>"},{"location":"pages/usage/pagination/","title":"Pagination","text":""},{"location":"pages/usage/pagination/#pagination-documents-matching-the-filter","title":"Pagination documents matching the filter","text":"main.py<pre><code>\"\"\"Pagination documents matching the filter.\n\nPagination is used to separate long sets of data so\nthat it is easier for a user to consume information.\n\nThe search is based on the effect of a quantum loop.\nThe search effectiveness depends on the number of processor threads.\n\"\"\"\n\nimport anyio\nfrom typing import Annotated\nfrom pydantic import Field\nfrom scruby import Scruby, ScrubyModel, settings\nfrom pprint import pprint as pp\n\nsettings.DB_ROOT = \"ScrubyDB\"  # By default = \"ScrubyDB\"\nsettings.HASH_REDUCE_LEFT = 6  # By default = 6\nsettings.MAX_WORKERS = None  # By default = None\n\n\nclass Car(ScrubyModel):\n    \"\"\"Car model.\"\"\"\n    brand: str = Field(strict=True, frozen=True)\n    model: str = Field(strict=True, frozen=True)\n    year: int = Field(strict=True)\n    power_reserve: int = Field(strict=True)\n    # key is always at bottom\n    key: str = Field(\n        strict=True,\n        frozen=True,\n        default_factory=lambda data: f\"{data['brand']}:{data['model']}\",\n    )\n\n\nasync def main() -&gt; None:\n    \"\"\"Example.\"\"\"\n    # Get collection `Car`.\n    car_coll = await Scruby.collection(Car)\n\n    # Create cars.\n    for num in range(1, 10):\n        car = Car(\n            brand=\"Mazda\",\n            model=f\"EZ-6 {num}\",\n            year=2025,\n            power_reserve=600,\n        )\n        await car_coll.add_doc(car)\n\n    # Pagination.\n    car_list: list[Car] | None = await car_coll.find_many(\n        filter_fn=lambda doc: doc.brand == \"Mazda\",\n        limit_docs=5,\n        page_number=2,\n    )\n    if car_list is not None:\n        pp(car_list)\n    else:\n        print(\"No cars!\")\n\n    # Full database deletion.\n    # Hint: The main purpose is tests.\n    Scruby.napalm()\n\n\nif __name__ == \"__main__\":\n    anyio.run(main)\n</code></pre>"},{"location":"pages/usage/plugins/","title":"Plugins","text":"main.py"},{"location":"pages/usage/update_documents/","title":"Update documents","text":""},{"location":"pages/usage/update_documents/#update-documents","title":"Update documents","text":"main.py<pre><code>\"\"\"Update one or more documents matching the filter.\n\nThe search is based on the effect of a quantum loop.\nThe search effectiveness depends on the number of processor threads.\n\"\"\"\n\nimport anyio\nfrom datetime import datetime\nfrom typing import Annotated\nfrom pydantic import EmailStr, Field\nfrom pydantic_extra_types.phone_numbers import PhoneNumber, PhoneNumberValidator\nfrom scruby import Scruby, ScrubyModel, settings\n\nsettings.DB_ROOT = \"ScrubyDB\"  # By default = \"ScrubyDB\"\nsettings.HASH_REDUCE_LEFT = 6  # By default = 6\nsettings.MAX_WORKERS = None  # By default = None\n\n\nclass User(ScrubyModel):\n    \"\"\"User model.\"\"\"\n\n    first_name: str = Field(strict=True)\n    last_name: str = Field(strict=True)\n    birthday: datetime = Field(strict=True)\n    email: EmailStr = Field(strict=True)\n    phone: Annotated[PhoneNumber, PhoneNumberValidator(number_format=\"E164\")] = Field(frozen=True)\n    # key is always at bottom\n    key: str = Field(\n        strict=True,\n        frozen=True,\n        default_factory=lambda data: data[\"phone\"],\n    )\n\n\nasync def main() -&gt; None:\n    \"\"\"Example.\"\"\"\n    # Get collection `User`.\n    user_coll = await Scruby.collection(User)\n\n    # Create users.\n    for num in range(1, 10):\n        user = User(\n            first_name=\"John\",\n            last_name=\"Smith\",\n            birthday=datetime(1970, 1, num, tzinfo=ZoneInfo(\"UTC\")),\n            email=f\"John_Smith_{num}@gmail.com\",\n            phone=f\"+44798612345{num}\",\n        )\n        await db.add_doc(user)\n\n    number_updated_users = await user_coll.update_many(\n        new_data={\"first_name\": \"Georg\"},\n    )\n    print(number_updated_users)  # =&gt; 9\n\n    users: list[User] | None = await user_coll.find_many()\n    for user in users:\n        print(user.first_name)  # =&gt; Georg\n\n    # Full database deletion.\n    # Hint: The main purpose is tests.\n    Scruby.napalm()\n\n\nif __name__ == \"__main__\":\n    anyio.run(main)\n</code></pre>"},{"location":"pages/usage/working_with_keys/","title":"Working with keys","text":""},{"location":"pages/usage/working_with_keys/#working-with-keys","title":"Working with keys","text":"main.py<pre><code>\"\"\"Working with keys.\"\"\"\n\nimport anyio\nfrom datetime import datetime\nfrom zoneinfo import ZoneInfo\nfrom typing import Annotated\nfrom pydantic import EmailStr, Field\nfrom pydantic_extra_types.phone_numbers import PhoneNumber, PhoneNumberValidator\nfrom scruby import Scruby, ScrubyModel, settings\n\nsettings.DB_ROOT = \"ScrubyDB\"  # By default = \"ScrubyDB\"\nsettings.HASH_REDUCE_LEFT = 6  # By default = 6\nsettings.MAX_WORKERS = None  # By default = None\n\n\nclass User(ScrubyModel):\n    \"\"\"User model.\"\"\"\n\n    first_name: str = Field(strict=True)\n    last_name: str = Field(strict=True)\n    birthday: datetime = Field(strict=True)\n    email: EmailStr = Field(strict=True)\n    phone: Annotated[PhoneNumber, PhoneNumberValidator(number_format=\"E164\")] = Field(frozen=True)\n    # key is always at bottom\n    key: str = Field(\n        strict=True,\n        frozen=True,\n        default_factory=lambda data: data[\"phone\"],\n    )\n\n\nasync def main() -&gt; None:\n    \"\"\"Example.\"\"\"\n    # Get collection `User`.\n    user_coll = await Scruby.collection(User)\n\n    # Create user.\n    user = User(\n        first_name=\"John\",\n        last_name=\"Smith\",\n        birthday=datetime(1970, 1, 1, tzinfo=ZoneInfo(\"UTC\")),\n        email=\"John_Smith@gmail.com\",\n        phone=\"+447986123456\",\n    )\n    # Add data of user to collection.\n    await user_coll.add_doc(user)\n\n    # Update data of  user to collection.\n    await user_coll.update_doc(user)\n\n    # Get user from collection.\n    await user_coll.get_doc(\"+447986123456\")  # =&gt; user\n    await user_coll.get_doc(\"key missing\")  # =&gt; KeyError\n\n    await user_coll.has_key(\"+447986123456\")  # =&gt; True\n    await user_coll.has_key(\"key missing\")  # =&gt; False\n\n    await user_coll.delete_doc(\"+447986123456\")\n    await user_coll.delete_doc(\"+447986123456\")  # =&gt; KeyError\n    await user_coll.delete_doc(\"key missing\")  # =&gt; KeyError\n\n    # Full database deletion.\n    # Hint: The main purpose is tests.\n    Scruby.napalm()\n\n\nif __name__ == \"__main__\":\n    anyio.run(main)\n</code></pre>"}]}