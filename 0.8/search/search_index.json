{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Scruby","text":"<p> A fast key-value storage library. <p> </p> </p> <p></p> <p> Scruby is a fast key-value storage asynchronous library that provides an ordered mapping from string keys to string values. The library uses fractal-tree addressing.   The database consists of collections. The maximum size of the one collection is 16\\*\\*8=4294967296 branches, each branch can store one or more keys.   The value of any key in collection can be obtained in 8 steps, thereby achieving high performance.   In the future, to search by value of key, the use of a quantum loop is supposed. </p> <p></p>"},{"location":"#requirements","title":"Requirements","text":"<p>View the list of requirements.</p>"},{"location":"#changelog","title":"Changelog","text":"<p>View the change history.</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT.</p>"},{"location":"pages/constants/","title":"Constants","text":"<p>Constant variables.</p> <p>The module contains the following variables:</p> <ul> <li><code>DB_ROOT</code> - Path to root directory of database. <code>By default = \"ScrubyDB\"</code> (in root of project).</li> <li><code>LENGTH_REDUCTION_HASH</code> - The length of the hash reduction on the left side.<ul> <li><code>0</code> - 4294967296 branches in collection (by default).</li> <li><code>2</code> - 16777216 branches in collection\u044e</li> <li><code>4</code> - 65536 branches in collection\u044e</li> <li><code>6</code> - 256 branches in collection (main purpose is tests).</li> </ul> </li> </ul>"},{"location":"pages/db/","title":"Details","text":"<p>Creation and management of the database.</p>"},{"location":"pages/db/#scruby.db.Scruby","title":"<code>Scruby</code>","text":"<p>Creation and management of database.</p> <p>Parameters:</p> Name Type Description Default <code>class_model</code> <code>T</code> <p>Class of Model (Pydantic).</p> required Source code in <code>src\\scruby\\db.py</code> <pre><code>class Scruby[T]:\n    \"\"\"Creation and management of database.\n\n    Args:\n        class_model: Class of Model (Pydantic).\n    \"\"\"\n\n    def __init__(  # noqa: D107\n        self,\n        class_model: T,\n    ) -&gt; None:\n        self.__class_model = class_model\n        self.__db_root = constants.DB_ROOT\n        self.__length_reduction_hash = constants.LENGTH_REDUCTION_HASH\n        # The maximum number of keys.\n        match self.__length_reduction_hash:\n            case 0:\n                self.__max_num_keys = 4294967296\n            case 2:\n                self.__max_num_keys = 16777216\n            case 4:\n                self.__max_num_keys = 65536\n            case 6:\n                self.__max_num_keys = 256\n            case _ as unreachable:\n                assert_never(Never(unreachable))\n\n    async def get_leaf_path(self, key: str) -&gt; Path:\n        \"\"\"Asynchronous method for getting path to collection cell by key.\n\n        Args:\n            key: Key name.\n        \"\"\"\n        if not isinstance(key, str):\n            raise KeyError(\"The key is not a type of `str`.\")\n        if len(key) == 0:\n            raise KeyError(\"The key should not be empty.\")\n        # Key to crc32 sum.\n        key_as_hash: str = f\"{zlib.crc32(key.encode('utf-8')):08x}\"[self.__length_reduction_hash :]\n        # Convert crc32 sum in the segment of path.\n        separated_hash: str = \"/\".join(list(key_as_hash))\n        # The path of the branch to the database.\n        branch_path: Path = Path(\n            *(\n                self.__db_root,\n                self.__class_model.__name__,\n                separated_hash,\n            ),\n        )\n        # If the branch does not exist, need to create it.\n        if not await branch_path.exists():\n            await branch_path.mkdir(parents=True)\n        # The path to the database cell.\n        leaf_path: Path = Path(*(branch_path, \"leaf.json\"))\n        return leaf_path\n\n    async def set_key(\n        self,\n        key: str,\n        value: T,\n    ) -&gt; None:\n        \"\"\"Asynchronous method for adding and updating keys to collection.\n\n        Args:\n            key: Key name.\n            value: Value of key.\n        \"\"\"\n        # The path to the database cell.\n        leaf_path: Path = await self.get_leaf_path(key)\n        value_json: str = value.model_dump_json()\n        # Write key-value to the database.\n        if await leaf_path.exists():\n            # Add new key or update existing.\n            data_json: bytes = await leaf_path.read_bytes()\n            data: dict = orjson.loads(data_json) or {}\n            data[key] = value_json\n            await leaf_path.write_bytes(orjson.dumps(data))\n        else:\n            # Add new key to a blank leaf.\n            await leaf_path.write_bytes(orjson.dumps({key: value_json}))\n\n    async def get_key(self, key: str) -&gt; T:\n        \"\"\"Asynchronous method for getting value of key from collection.\n\n        Args:\n            key: Key name.\n        \"\"\"\n        # The path to the database cell.\n        leaf_path: Path = await self.get_leaf_path(key)\n        # Get value of key.\n        if await leaf_path.exists():\n            data_json: bytes = await leaf_path.read_bytes()\n            data: dict = orjson.loads(data_json) or {}\n            obj: T = self.__class_model.model_validate_json(data[key])\n            return obj\n        raise KeyError()\n\n    async def has_key(self, key: str) -&gt; bool:\n        \"\"\"Asynchronous method for checking presence of key in collection.\n\n        Args:\n            key: Key name.\n        \"\"\"\n        # The path to the database cell.\n        leaf_path: Path = await self.get_leaf_path(key)\n        # Checking whether there is a key.\n        if await leaf_path.exists():\n            data_json: bytes = await leaf_path.read_bytes()\n            data: dict = orjson.loads(data_json) or {}\n            try:\n                data[key]\n                return True\n            except KeyError:\n                return False\n        return False\n\n    async def delete_key(self, key: str) -&gt; None:\n        \"\"\"Asynchronous method for deleting key from collection.\n\n        Args:\n            key: Key name.\n        \"\"\"\n        # The path to the database cell.\n        leaf_path: Path = await self.get_leaf_path(key)\n        # Deleting key.\n        if await leaf_path.exists():\n            data_json: bytes = await leaf_path.read_bytes()\n            data: dict = orjson.loads(data_json) or {}\n            del data[key]\n            await leaf_path.write_bytes(orjson.dumps(data))\n            return\n        raise KeyError()\n\n    @staticmethod\n    async def napalm() -&gt; None:\n        \"\"\"Asynchronous method for full database deletion.\n\n        The main purpose is tests.\n\n        Warning:\n            - `Be careful, this will remove all keys.`\n        \"\"\"\n        with contextlib.suppress(FileNotFoundError):\n            await to_thread.run_sync(rmtree, constants.DB_ROOT)\n        return\n\n    @staticmethod\n    def search_task(\n        key: int,\n        filter_fn: Callable,\n        length_reduction_hash: str,\n        db_root: str,\n        class_model: T,\n    ) -&gt; dict[str, Any] | None:\n        \"\"\"Search task.\"\"\"\n        key_as_hash: str = f\"{key:08x}\"[length_reduction_hash:]\n        separated_hash: str = \"/\".join(list(key_as_hash))\n        leaf_path: SyncPath = SyncPath(\n            *(\n                db_root,\n                class_model.__name__,\n                separated_hash,\n                \"leaf.json\",\n            ),\n        )\n        if leaf_path.exists():\n            data_json: bytes = leaf_path.read_bytes()\n            data: dict[str, str] = orjson.loads(data_json) or {}\n            for _, val in data.items():\n                doc = class_model.model_validate_json(val)\n                if filter_fn(doc):\n                    return doc\n        return None\n\n    def find_one(\n        self,\n        filter_fn: Callable,\n        max_workers: int | None = None,\n        timeout: float | None = None,\n    ) -&gt; T | None:\n        \"\"\"Find a single document.\n\n        The search is based on the effect of a quantum loop.\n        The search effectiveness depends on the number of processor threads.\n        Ideally, hundreds and even thousands of threads are required.\n\n        Args:\n            filter_fn: A function that execute the conditions of filtering.\n            max_workers: The maximum number of processes that can be used to\n                         execute the given calls. If None or not given then as many\n                         worker processes will be created as the machine has processors.\n            timeout: The number of seconds to wait for the result if the future isn't done.\n                     If None, then there is no limit on the wait time.\n        \"\"\"\n        keys: range = range(1, self.__max_num_keys)\n        search_task_fn: Callable = self.search_task\n        length_reduction_hash: int = self.__length_reduction_hash\n        db_root: str = self.__db_root\n        class_model: T = self.__class_model\n        with concurrent.futures.ThreadPoolExecutor(max_workers) as executor:\n            for key in keys:\n                future = executor.submit(\n                    search_task_fn,\n                    key,\n                    filter_fn,\n                    length_reduction_hash,\n                    db_root,\n                    class_model,\n                )\n                doc = future.result(timeout)\n                if doc is not None:\n                    return doc\n        return None\n\n    def find_many(\n        self,\n        filter_fn: Callable,\n        db_query_docs_limit: int = 1000,\n        max_workers: int | None = None,\n        timeout: float | None = None,\n    ) -&gt; list[T] | None:\n        \"\"\"Find documents.\n\n        The search is based on the effect of a quantum loop.\n        The search effectiveness depends on the number of processor threads.\n        Ideally, hundreds and even thousands of threads are required.\n\n        Args:\n            filter_fn: A function that execute the conditions of filtering.\n            db_query_docs_limit: Limiting the number of request results. By default = 1000.\n            max_workers: The maximum number of processes that can be used to\n                         execute the given calls. If None or not given then as many\n                         worker processes will be created as the machine has processors.\n            timeout: The number of seconds to wait for the result if the future isn't done.\n                     If None, then there is no limit on the wait time.\n        \"\"\"\n        keys: range = range(1, self.__max_num_keys)\n        search_task_fn: Callable = self.search_task\n        length_reduction_hash: int = self.__length_reduction_hash\n        db_root: str = self.__db_root\n        class_model: T = self.__class_model\n        counter: int = 0\n        with concurrent.futures.ThreadPoolExecutor(max_workers) as executor:\n            results = []\n            for key in keys:\n                if counter == db_query_docs_limit:\n                    break\n                future = executor.submit(\n                    search_task_fn,\n                    key,\n                    filter_fn,\n                    length_reduction_hash,\n                    db_root,\n                    class_model,\n                )\n                doc = future.result(timeout)\n                if doc is not None:\n                    results.append(doc)\n                    counter += 1\n        return results or None\n</code></pre>"},{"location":"pages/db/#scruby.db.Scruby.delete_key","title":"<code>delete_key(key)</code>  <code>async</code>","text":"<p>Asynchronous method for deleting key from collection.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Key name.</p> required Source code in <code>src\\scruby\\db.py</code> <pre><code>async def delete_key(self, key: str) -&gt; None:\n    \"\"\"Asynchronous method for deleting key from collection.\n\n    Args:\n        key: Key name.\n    \"\"\"\n    # The path to the database cell.\n    leaf_path: Path = await self.get_leaf_path(key)\n    # Deleting key.\n    if await leaf_path.exists():\n        data_json: bytes = await leaf_path.read_bytes()\n        data: dict = orjson.loads(data_json) or {}\n        del data[key]\n        await leaf_path.write_bytes(orjson.dumps(data))\n        return\n    raise KeyError()\n</code></pre>"},{"location":"pages/db/#scruby.db.Scruby.find_many","title":"<code>find_many(filter_fn, db_query_docs_limit=1000, max_workers=None, timeout=None)</code>","text":"<p>Find documents.</p> <p>The search is based on the effect of a quantum loop. The search effectiveness depends on the number of processor threads. Ideally, hundreds and even thousands of threads are required.</p> <p>Parameters:</p> Name Type Description Default <code>filter_fn</code> <code>Callable</code> <p>A function that execute the conditions of filtering.</p> required <code>db_query_docs_limit</code> <code>int</code> <p>Limiting the number of request results. By default = 1000.</p> <code>1000</code> <code>max_workers</code> <code>int | None</code> <p>The maximum number of processes that can be used to          execute the given calls. If None or not given then as many          worker processes will be created as the machine has processors.</p> <code>None</code> <code>timeout</code> <code>float | None</code> <p>The number of seconds to wait for the result if the future isn't done.      If None, then there is no limit on the wait time.</p> <code>None</code> Source code in <code>src\\scruby\\db.py</code> <pre><code>def find_many(\n    self,\n    filter_fn: Callable,\n    db_query_docs_limit: int = 1000,\n    max_workers: int | None = None,\n    timeout: float | None = None,\n) -&gt; list[T] | None:\n    \"\"\"Find documents.\n\n    The search is based on the effect of a quantum loop.\n    The search effectiveness depends on the number of processor threads.\n    Ideally, hundreds and even thousands of threads are required.\n\n    Args:\n        filter_fn: A function that execute the conditions of filtering.\n        db_query_docs_limit: Limiting the number of request results. By default = 1000.\n        max_workers: The maximum number of processes that can be used to\n                     execute the given calls. If None or not given then as many\n                     worker processes will be created as the machine has processors.\n        timeout: The number of seconds to wait for the result if the future isn't done.\n                 If None, then there is no limit on the wait time.\n    \"\"\"\n    keys: range = range(1, self.__max_num_keys)\n    search_task_fn: Callable = self.search_task\n    length_reduction_hash: int = self.__length_reduction_hash\n    db_root: str = self.__db_root\n    class_model: T = self.__class_model\n    counter: int = 0\n    with concurrent.futures.ThreadPoolExecutor(max_workers) as executor:\n        results = []\n        for key in keys:\n            if counter == db_query_docs_limit:\n                break\n            future = executor.submit(\n                search_task_fn,\n                key,\n                filter_fn,\n                length_reduction_hash,\n                db_root,\n                class_model,\n            )\n            doc = future.result(timeout)\n            if doc is not None:\n                results.append(doc)\n                counter += 1\n    return results or None\n</code></pre>"},{"location":"pages/db/#scruby.db.Scruby.find_one","title":"<code>find_one(filter_fn, max_workers=None, timeout=None)</code>","text":"<p>Find a single document.</p> <p>The search is based on the effect of a quantum loop. The search effectiveness depends on the number of processor threads. Ideally, hundreds and even thousands of threads are required.</p> <p>Parameters:</p> Name Type Description Default <code>filter_fn</code> <code>Callable</code> <p>A function that execute the conditions of filtering.</p> required <code>max_workers</code> <code>int | None</code> <p>The maximum number of processes that can be used to          execute the given calls. If None or not given then as many          worker processes will be created as the machine has processors.</p> <code>None</code> <code>timeout</code> <code>float | None</code> <p>The number of seconds to wait for the result if the future isn't done.      If None, then there is no limit on the wait time.</p> <code>None</code> Source code in <code>src\\scruby\\db.py</code> <pre><code>def find_one(\n    self,\n    filter_fn: Callable,\n    max_workers: int | None = None,\n    timeout: float | None = None,\n) -&gt; T | None:\n    \"\"\"Find a single document.\n\n    The search is based on the effect of a quantum loop.\n    The search effectiveness depends on the number of processor threads.\n    Ideally, hundreds and even thousands of threads are required.\n\n    Args:\n        filter_fn: A function that execute the conditions of filtering.\n        max_workers: The maximum number of processes that can be used to\n                     execute the given calls. If None or not given then as many\n                     worker processes will be created as the machine has processors.\n        timeout: The number of seconds to wait for the result if the future isn't done.\n                 If None, then there is no limit on the wait time.\n    \"\"\"\n    keys: range = range(1, self.__max_num_keys)\n    search_task_fn: Callable = self.search_task\n    length_reduction_hash: int = self.__length_reduction_hash\n    db_root: str = self.__db_root\n    class_model: T = self.__class_model\n    with concurrent.futures.ThreadPoolExecutor(max_workers) as executor:\n        for key in keys:\n            future = executor.submit(\n                search_task_fn,\n                key,\n                filter_fn,\n                length_reduction_hash,\n                db_root,\n                class_model,\n            )\n            doc = future.result(timeout)\n            if doc is not None:\n                return doc\n    return None\n</code></pre>"},{"location":"pages/db/#scruby.db.Scruby.get_key","title":"<code>get_key(key)</code>  <code>async</code>","text":"<p>Asynchronous method for getting value of key from collection.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Key name.</p> required Source code in <code>src\\scruby\\db.py</code> <pre><code>async def get_key(self, key: str) -&gt; T:\n    \"\"\"Asynchronous method for getting value of key from collection.\n\n    Args:\n        key: Key name.\n    \"\"\"\n    # The path to the database cell.\n    leaf_path: Path = await self.get_leaf_path(key)\n    # Get value of key.\n    if await leaf_path.exists():\n        data_json: bytes = await leaf_path.read_bytes()\n        data: dict = orjson.loads(data_json) or {}\n        obj: T = self.__class_model.model_validate_json(data[key])\n        return obj\n    raise KeyError()\n</code></pre>"},{"location":"pages/db/#scruby.db.Scruby.get_leaf_path","title":"<code>get_leaf_path(key)</code>  <code>async</code>","text":"<p>Asynchronous method for getting path to collection cell by key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Key name.</p> required Source code in <code>src\\scruby\\db.py</code> <pre><code>async def get_leaf_path(self, key: str) -&gt; Path:\n    \"\"\"Asynchronous method for getting path to collection cell by key.\n\n    Args:\n        key: Key name.\n    \"\"\"\n    if not isinstance(key, str):\n        raise KeyError(\"The key is not a type of `str`.\")\n    if len(key) == 0:\n        raise KeyError(\"The key should not be empty.\")\n    # Key to crc32 sum.\n    key_as_hash: str = f\"{zlib.crc32(key.encode('utf-8')):08x}\"[self.__length_reduction_hash :]\n    # Convert crc32 sum in the segment of path.\n    separated_hash: str = \"/\".join(list(key_as_hash))\n    # The path of the branch to the database.\n    branch_path: Path = Path(\n        *(\n            self.__db_root,\n            self.__class_model.__name__,\n            separated_hash,\n        ),\n    )\n    # If the branch does not exist, need to create it.\n    if not await branch_path.exists():\n        await branch_path.mkdir(parents=True)\n    # The path to the database cell.\n    leaf_path: Path = Path(*(branch_path, \"leaf.json\"))\n    return leaf_path\n</code></pre>"},{"location":"pages/db/#scruby.db.Scruby.has_key","title":"<code>has_key(key)</code>  <code>async</code>","text":"<p>Asynchronous method for checking presence of key in collection.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Key name.</p> required Source code in <code>src\\scruby\\db.py</code> <pre><code>async def has_key(self, key: str) -&gt; bool:\n    \"\"\"Asynchronous method for checking presence of key in collection.\n\n    Args:\n        key: Key name.\n    \"\"\"\n    # The path to the database cell.\n    leaf_path: Path = await self.get_leaf_path(key)\n    # Checking whether there is a key.\n    if await leaf_path.exists():\n        data_json: bytes = await leaf_path.read_bytes()\n        data: dict = orjson.loads(data_json) or {}\n        try:\n            data[key]\n            return True\n        except KeyError:\n            return False\n    return False\n</code></pre>"},{"location":"pages/db/#scruby.db.Scruby.napalm","title":"<code>napalm()</code>  <code>async</code> <code>staticmethod</code>","text":"<p>Asynchronous method for full database deletion.</p> <p>The main purpose is tests.</p> Warning <ul> <li><code>Be careful, this will remove all keys.</code></li> </ul> Source code in <code>src\\scruby\\db.py</code> <pre><code>@staticmethod\nasync def napalm() -&gt; None:\n    \"\"\"Asynchronous method for full database deletion.\n\n    The main purpose is tests.\n\n    Warning:\n        - `Be careful, this will remove all keys.`\n    \"\"\"\n    with contextlib.suppress(FileNotFoundError):\n        await to_thread.run_sync(rmtree, constants.DB_ROOT)\n    return\n</code></pre>"},{"location":"pages/db/#scruby.db.Scruby.search_task","title":"<code>search_task(key, filter_fn, length_reduction_hash, db_root, class_model)</code>  <code>staticmethod</code>","text":"<p>Search task.</p> Source code in <code>src\\scruby\\db.py</code> <pre><code>@staticmethod\ndef search_task(\n    key: int,\n    filter_fn: Callable,\n    length_reduction_hash: str,\n    db_root: str,\n    class_model: T,\n) -&gt; dict[str, Any] | None:\n    \"\"\"Search task.\"\"\"\n    key_as_hash: str = f\"{key:08x}\"[length_reduction_hash:]\n    separated_hash: str = \"/\".join(list(key_as_hash))\n    leaf_path: SyncPath = SyncPath(\n        *(\n            db_root,\n            class_model.__name__,\n            separated_hash,\n            \"leaf.json\",\n        ),\n    )\n    if leaf_path.exists():\n        data_json: bytes = leaf_path.read_bytes()\n        data: dict[str, str] = orjson.loads(data_json) or {}\n        for _, val in data.items():\n            doc = class_model.model_validate_json(val)\n            if filter_fn(doc):\n                return doc\n    return None\n</code></pre>"},{"location":"pages/db/#scruby.db.Scruby.set_key","title":"<code>set_key(key, value)</code>  <code>async</code>","text":"<p>Asynchronous method for adding and updating keys to collection.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Key name.</p> required <code>value</code> <code>T</code> <p>Value of key.</p> required Source code in <code>src\\scruby\\db.py</code> <pre><code>async def set_key(\n    self,\n    key: str,\n    value: T,\n) -&gt; None:\n    \"\"\"Asynchronous method for adding and updating keys to collection.\n\n    Args:\n        key: Key name.\n        value: Value of key.\n    \"\"\"\n    # The path to the database cell.\n    leaf_path: Path = await self.get_leaf_path(key)\n    value_json: str = value.model_dump_json()\n    # Write key-value to the database.\n    if await leaf_path.exists():\n        # Add new key or update existing.\n        data_json: bytes = await leaf_path.read_bytes()\n        data: dict = orjson.loads(data_json) or {}\n        data[key] = value_json\n        await leaf_path.write_bytes(orjson.dumps(data))\n    else:\n        # Add new key to a blank leaf.\n        await leaf_path.write_bytes(orjson.dumps({key: value_json}))\n</code></pre>"},{"location":"pages/installation/","title":"Installation","text":"<pre><code>uv add scruby\n</code></pre>"},{"location":"pages/usage/","title":"Usage","text":""},{"location":"pages/usage/#working-with-keys","title":"Working with keys","text":"main.py<pre><code>import anyio\nimport datetime\nfrom pydantic import BaseModel, EmailStr\nfrom pydantic_extra_types.phone_numbers import PhoneNumber\nfrom scruby import Scruby, constants\n\nconstants.DB_ROOT = \"ScrubyDB\"  # By default = \"ScrubyDB\"\n\nclass User(BaseModel):\n    \"\"\"Model of User.\"\"\"\n    first_name: str\n    last_name: str\n    birthday: datetime.datetime\n    email: EmailStr\n    phone: PhoneNumber\n\nasync def main() -&gt; None:\n    \"\"\"Example.\"\"\"\n    # Get collection of `User`.\n    user_coll = Scruby(User)\n\n    # Create user.\n    user = User(\n        first_name=\"John\",\n        last_name=\"Smith\",\n        birthday=datetime.datetime(1970, 1, 1),\n        email=\"John_Smith@gmail.com\",\n        phone=\"+447986123456\",\n    )\n\n    # Add user to collection.\n    await user_coll.set_key(\"+447986123456\", user)\n\n    # Get user from collection.\n    await user_coll.get_key(\"+447986123456\")  # =&gt; user\n    await user_coll.get_key(\"key missing\")  # =&gt; KeyError\n\n    await user_coll.has_key(\"+447986123456\")  # =&gt; True\n    await user_coll.has_key(\"key missing\")  # =&gt; False\n\n    await user_coll.delete_key(\"+447986123456\")\n    await user_coll.delete_key(\"+447986123456\")  # =&gt; KeyError\n    await user_coll.delete_key(\"key missing\")  # =&gt; KeyError\n\n    # Full database deletion.\n    # Hint: The main purpose is tests.\n    await Scruby.napalm()\n\nif __name__ == \"__main__\":\n    anyio.run(main)\n</code></pre>"},{"location":"pages/usage/#find-a-single-document","title":"Find a single document","text":"main.py<pre><code>\"\"\"Find a single document.\n\nThe search is based on the effect of a quantum loop.\nThe search effectiveness depends on the number of processor threads.\nIdeally, hundreds and even thousands of threads are required.\n\"\"\"\n\nimport anyio\nimport datetime\nfrom pydantic import BaseModel, EmailStr\nfrom pydantic_extra_types.phone_numbers import PhoneNumber\nfrom scruby import Scruby, constants\nfrom pprint import pprint as pp\n\nconstants.DB_ROOT = \"ScrubyDB\"  # By default = \"ScrubyDB\"\nconstants.LENGTH_REDUCTION_HASH = 6  # 256 branches in collection\n                                     # (main purpose is tests).\n\nclass User(BaseModel):\n    \"\"\"Model of User.\"\"\"\n    first_name: str\n    last_name: str\n    birthday: datetime.datetime\n    email: EmailStr\n    phone: PhoneNumber\n\nasync def main() -&gt; None:\n    \"\"\"Example.\"\"\"\n    # Get collection of `User`.\n    user_coll = Scruby(User)\n\n    # Create user.\n    user = User(\n        first_name=\"John\",\n        last_name=\"Smith\",\n        birthday=datetime.datetime(1970, 1, 1),\n        email=\"John_Smith@gmail.com\",\n        phone=\"+447986123456\",\n    )\n\n    # Add user to collection.\n    await user_coll.set_key(\"+447986123456\", user)\n\n    # Find user by email.\n    user_details: User | None = user_coll.find_one(\n        filter_fn=lambda doc: doc.email == \"John_Smith@gmail.com\",\n    )\n    if user_details is not None:\n        pp(user_details)\n    else:\n        print(\"No User!\")\n\n    # Find user by birthday.\n    user_details: User | None = user_coll.find_one(\n        filter_fn=lambda doc: doc.birthday == datetime.datetime(1970, 1, 1),\n    )\n    if user_details is not None:\n        pp(user_details)\n    else:\n        print(\"No User!\")\n\n    # Full database deletion.\n    # Hint: The main purpose is tests.\n    await Scruby.napalm()\n\nif __name__ == \"__main__\":\n    anyio.run(main)\n</code></pre>"},{"location":"pages/usage/#find-documents","title":"Find documents","text":"main.py<pre><code>\"\"\"Find documents.\n\nThe search is based on the effect of a quantum loop.\nThe search effectiveness depends on the number of processor threads.\nIdeally, hundreds and even thousands of threads are required.\n\"\"\"\n\nimport anyio\nimport datetime\nfrom pydantic import BaseModel, EmailStr\nfrom pydantic_extra_types.phone_numbers import PhoneNumber\nfrom scruby import Scruby, constants\nfrom pprint import pprint as pp\n\nconstants.DB_ROOT = \"ScrubyDB\"  # By default = \"ScrubyDB\"\nconstants.LENGTH_REDUCTION_HASH = 6  # 256 branches in collection\n                                     # (main purpose is tests).\n\nclass User(BaseModel):\n    \"\"\"Model of User.\"\"\"\n    first_name: str\n    last_name: str\n    birthday: datetime.datetime\n    email: EmailStr\n    phone: PhoneNumber\n\nasync def main() -&gt; None:\n    \"\"\"Example.\"\"\"\n    # Get collection of `User`.\n    user_coll = Scruby(User)\n\n    # Create users.\n    for num in range(1, 10):\n        user = User(\n            first_name=\"John\",\n            last_name=\"Smith\",\n            birthday=datetime.datetime(1970, 1, num),\n            email=f\"John_Smith_{num}@gmail.com\",\n            phone=f\"+44798612345{num}\",\n        )\n        await db.set_key(f\"+44798612345{num}\", user)\n\n    # Find users by email.\n    users: list[User] | None = user_coll.find_many(\n        filter_fn=lambda doc: doc.email == \"John_Smith_5@gmail.com\" or doc.email == \"John_Smith_8@gmail.com\",\n    )\n    if users is not None:\n        pp(users)\n    else:\n        print(\"No users!\")\n\n    # Full database deletion.\n    # Hint: The main purpose is tests.\n    await Scruby.napalm()\n\nif __name__ == \"__main__\":\n    anyio.run(main)\n</code></pre>"}]}